{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 定义基本工具函数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-11T11:37:44.803209Z",
     "start_time": "2025-03-11T11:37:16.066540Z"
    },
    "execution": {
     "iopub.execute_input": "2025-03-11T00:42:25.727200Z",
     "iopub.status.busy": "2025-03-11T00:42:25.726839Z",
     "iopub.status.idle": "2025-03-11T00:42:26.921710Z",
     "shell.execute_reply": "2025-03-11T00:42:26.920962Z",
     "shell.execute_reply.started": "2025-03-11T00:42:25.727182Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\22273\\AppData\\Roaming\\Python\\Python311\\site-packages\\paddle\\utils\\cpp_extension\\extension_utils.py:711: UserWarning: No ccache found. Please be aware that recompiling all source files may be required. You can download and install ccache from: https://github.com/ccache/ccache/blob/master/doc/INSTALL.md\n",
      "  warnings.warn(warning_message)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loaded training data...\n",
      "样本长度： 4240\n",
      "字表大小 1016\n"
     ]
    }
   ],
   "source": [
    "import numpy as np \n",
    "import paddle\n",
    "import paddle.nn.functional as F\n",
    "import time\n",
    "import random\n",
    "from collections import Counter\n",
    "\n",
    "RANDOM_SEED = 123\n",
    "paddle.seed(RANDOM_SEED)\n",
    "\n",
    "def elapsed(sec):\n",
    "    if sec < 60:\n",
    "        return str(sec) +\"sec\"\n",
    "    elif sec< 60*60:\n",
    "        return str(sec/60)+\"min\"\n",
    "    else :\n",
    "        return str(sec/(60*60)) +\"hr\"\n",
    "\n",
    "training_file = \"wordstest.txt\" #定义样本文件\n",
    "\n",
    "def readalltxt(txt_files):\n",
    "    labels = []\n",
    "    for txt_file in txt_files:\n",
    "        target = get_ch_lable(txt_file)\n",
    "        labels.append(target)\n",
    "\n",
    "    return training_file\n",
    "\n",
    "def get_ch_lable(txt_file):\n",
    "    labels = \"\"\n",
    "    with open(txt_file,\"rb\") as f:\n",
    "        # print(f) #<_io.BufferedReader name='wordstest.txt'>\n",
    "        for label in f:\n",
    "            labels = labels + label.decode(\"utf-8\")\n",
    "\n",
    "    return labels\n",
    "\n",
    "\n",
    "def get_ch_lable_v(txt_file,word_num_map,txt_label = None):\n",
    "    words_size = len(word_num_map)\n",
    "    to_num = lambda word:word_num_map.get(word,words_size)#如果word没有在训练集出现过，就输出words_size\n",
    "    if txt_file != None:\n",
    "        txt_label = get_ch_lable(txt_file)\n",
    "    labels_vector = list(map(to_num,txt_label))\n",
    "    return labels_vector\n",
    "\n",
    "training_data = get_ch_lable(training_file)\n",
    "print(\"loaded training data...\")\n",
    "\n",
    "print(\"样本长度：\",len(training_data))\n",
    "\n",
    "counter  = Counter(training_data)\n",
    "# print(counter)\n",
    "words = sorted(counter)\n",
    "# print(words)\n",
    "words_size = len(words)\n",
    "word_num_map = dict(zip(words,range(words_size))) # 字映射到对应的独热编码\n",
    "\n",
    "print(\"字表大小\",words_size)\n",
    "wordlabel = get_ch_lable_v(training_file,word_num_map)\n",
    "# print(wordlabel)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 模型主体"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-11T11:37:48.700993Z",
     "start_time": "2025-03-11T11:37:48.692551Z"
    },
    "execution": {
     "iopub.execute_input": "2025-03-11T00:42:26.923039Z",
     "iopub.status.busy": "2025-03-11T00:42:26.922693Z",
     "iopub.status.idle": "2025-03-11T00:42:26.928874Z",
     "shell.execute_reply": "2025-03-11T00:42:26.928324Z",
     "shell.execute_reply.started": "2025-03-11T00:42:26.923017Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "class GRURNN(paddle.nn.Layer):\n",
    "    def __init__(self,word_size,embed_dim,hidden_dim,output_size,num_layers):\n",
    "        super(GRURNN,self).__init__()\n",
    "        self.num_layers = num_layers\n",
    "        self.hidden_dim = hidden_dim\n",
    "\n",
    "        self.embed = paddle.nn.Embedding(word_size,embed_dim)\n",
    "        self.gru = paddle.nn.GRU(input_size=embed_dim,hidden_size=hidden_dim,num_layers=num_layers,direction = \"bidirectional\")\n",
    "        self.fc = paddle.nn.Linear(hidden_dim*2,output_size)#输出概率\n",
    "\n",
    "    def forward(self,features,hidden):\n",
    "        embedded = self.embed(features.reshape([1,-1]))\n",
    "        output,hidden = self.gru(embedded.reshape([1,1,-1]),hidden)\n",
    "        # output = self.attention(output)\n",
    "        output = self.fc(output.reshape([1,-1]))\n",
    "\n",
    "        return output,hidden\n",
    "\n",
    "    def init_zero_state(self):\n",
    "        init_hidden = paddle.zeros([self.num_layers*2,1,self.hidden_dim])\n",
    "\n",
    "        return init_hidden\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 训练前的小小准备"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-11T11:38:03.364791Z",
     "start_time": "2025-03-11T11:38:00.425971Z"
    },
    "execution": {
     "iopub.execute_input": "2025-03-11T00:42:26.929955Z",
     "iopub.status.busy": "2025-03-11T00:42:26.929617Z",
     "iopub.status.idle": "2025-03-11T00:42:26.938647Z",
     "shell.execute_reply": "2025-03-11T00:42:26.938126Z",
     "shell.execute_reply.started": "2025-03-11T00:42:26.929935Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "EMBEDDING_DIM = 10\n",
    "HIDDEN_DIM = 20\n",
    "NUM_LAYERS = 1\n",
    "\n",
    "model = GRURNN(words_size, EMBEDDING_DIM, HIDDEN_DIM, words_size, NUM_LAYERS)\n",
    "optimizer = paddle.optimizer.Adam(learning_rate=0.005,parameters=model.parameters())\n",
    "\n",
    "#定义测试函数\n",
    "def evaluate(model, prime_str, predict_len, temperature=0.8):\n",
    "\n",
    "    hidden = model.init_zero_state()\n",
    "    predicted = ''\n",
    "\n",
    "    #处理输入语义\n",
    "    for p in range(len(prime_str) - 1):\n",
    "        _, hidden = model(prime_str[p], hidden)\n",
    "        predicted +=words[prime_str[p]]\n",
    "    inp = prime_str[-1]\n",
    "    predicted +=words[inp]\n",
    "    \n",
    "    for p in range(predict_len):\n",
    "        output, hidden = model(inp, hidden)\n",
    "        \n",
    "        #从多项式分布中采样\n",
    "        output_dist = output.reshape([-1]).divide(paddle.to_tensor(temperature)).exp()\n",
    "        inp = paddle.multinomial(output_dist, 1)[0]\n",
    "        \n",
    "        predicted += words[inp]\n",
    "\n",
    "    return predicted"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 正式训练"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-11T11:44:12.218107Z",
     "start_time": "2025-03-11T11:43:32.093651Z"
    },
    "execution": {
     "iopub.execute_input": "2025-03-11T00:42:26.939696Z",
     "iopub.status.busy": "2025-03-11T00:42:26.939379Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time elapsed: 0.0009 min\n",
      "step 100 | Loss 6.07\n",
      "\n",
      "\n",
      "个不情愿的挣扎着起床，可是我们还是得用飞时，桑二飘，桥荆那帆事已醉少即的一手中。还的熟果追的季灰涌。即云 \n",
      "\n",
      "==================================================\n",
      "Time elapsed: 0.0009 min\n",
      "step 200 | Loss 7.00\n",
      "\n",
      "\n",
      "。朋友是要用关心去润泽，用勉励去雕琢，用而清年的分你，字中任自？，拉在锚张，铃逢丝只一晃游多的得视徘等时 \n",
      "\n",
      "==================================================\n",
      "Time elapsed: 0.0010 min\n",
      "step 300 | Loss 5.29\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "　　每一天的早晨我们还是需要坚强，画处，步可找\n",
      "又道，　　高需光的身豆展又的涌，晚效，迷响，有路棘 \n",
      "\n",
      "==================================================\n",
      "Time elapsed: 0.0010 min\n",
      "step 400 | Loss 5.84\n",
      "\n",
      "\n",
      "海遗珠，给予养分，欣赏长处，知己知彼，将的常百开时的秀名，终去幅者当留憧换，些呢碰仇在唯梦的扫候的睁憧了 \n",
      "\n",
      "==================================================\n",
      "Time elapsed: 0.0008 min\n",
      "step 500 | Loss 4.03\n",
      "\n",
      "\n",
      "效果，破坏双方的关系。\n",
      "\n",
      "　　每一天运的　们锚，鹜穿得缺比依，让一破一伤好离从新，请雨们寻连不己，但 \n",
      "\n",
      "==================================================\n",
      "Time elapsed: 0.0011 min\n",
      "step 600 | Loss 5.89\n",
      "\n",
      "\n",
      "复。发掘被埋没的那一颗沧海遗珠，给予养分的度己，注享跌慵触虚历能绕一修自程的时光，最谁桥吻的花享己的心复 \n",
      "\n",
      "==================================================\n",
      "Time elapsed: 0.0009 min\n",
      "step 700 | Loss 5.07\n",
      "\n",
      "\n",
      "巧，请辅以诚恳温和的态度，否则，忠言逆耳的时成，雁境的时花，习母一一昏泉少，只着　涛如度的笑使，\n",
      "\n",
      " \n",
      "\n",
      "==================================================\n",
      "Time elapsed: 0.0009 min\n",
      "step 800 | Loss 5.58\n",
      "\n",
      "\n",
      "你步向正途；损友会诱惑你走上歪路，令你陷的锈对，似枕了扣识的时奈，而拨的刹光前，伴的他邃，杯漂受人受舌的 \n",
      "\n",
      "==================================================\n",
      "Time elapsed: 0.0009 min\n",
      "step 900 | Loss 5.55\n",
      "\n",
      "\n",
      "面皮薄，请不要在大庭广众上指导，请配合先香的微潺观律是无奈的风雨或壶旧起，十伴着你的歌昏结，职而的间，我 \n",
      "\n",
      "==================================================\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[4], line 29\u001b[0m\n\u001b[0;32m     27\u001b[0m inputs, targets \u001b[38;5;241m=\u001b[39m paddle\u001b[38;5;241m.\u001b[39mto_tensor(inwords), paddle\u001b[38;5;241m.\u001b[39mto_tensor(out_onehot)\n\u001b[0;32m     28\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m c \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(n_input):\n\u001b[1;32m---> 29\u001b[0m     outputs, hidden \u001b[38;5;241m=\u001b[39m model(inputs[c], hidden)\n\u001b[0;32m     30\u001b[0m     loss \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m F\u001b[38;5;241m.\u001b[39mcross_entropy(outputs, targets[c]\u001b[38;5;241m.\u001b[39mreshape([\u001b[38;5;241m1\u001b[39m]))\n\u001b[0;32m     32\u001b[0m loss \u001b[38;5;241m/\u001b[39m\u001b[38;5;241m=\u001b[39m n_input\u001b[38;5;66;03m#求每个字的平均loss\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\paddle\\nn\\layer\\layers.py:1530\u001b[0m, in \u001b[0;36mLayer.__call__\u001b[1;34m(self, *inputs, **kwargs)\u001b[0m\n\u001b[0;32m   1521\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39minputs: Any, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs: Any) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Any:\n\u001b[0;32m   1522\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[0;32m   1523\u001b[0m         (\u001b[38;5;129;01mnot\u001b[39;00m in_to_static_mode())\n\u001b[0;32m   1524\u001b[0m         \u001b[38;5;129;01mand\u001b[39;00m (\u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks)\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1528\u001b[0m         \u001b[38;5;129;01mand\u001b[39;00m (\u001b[38;5;129;01mnot\u001b[39;00m in_profiler_mode() \u001b[38;5;129;01mor\u001b[39;00m in_sot_simulation_mode())\n\u001b[0;32m   1529\u001b[0m     ):\n\u001b[1;32m-> 1530\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mforward(\u001b[38;5;241m*\u001b[39minputs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1531\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   1532\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dygraph_call_func(\u001b[38;5;241m*\u001b[39minputs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "Cell \u001b[1;32mIn[2], line 13\u001b[0m, in \u001b[0;36mGRURNN.forward\u001b[1;34m(self, features, hidden)\u001b[0m\n\u001b[0;32m     11\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m,features,hidden):\n\u001b[0;32m     12\u001b[0m     embedded \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39membed(features\u001b[38;5;241m.\u001b[39mreshape([\u001b[38;5;241m1\u001b[39m,\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m]))\n\u001b[1;32m---> 13\u001b[0m     output,hidden \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgru(embedded\u001b[38;5;241m.\u001b[39mreshape([\u001b[38;5;241m1\u001b[39m,\u001b[38;5;241m1\u001b[39m,\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m]),hidden)\n\u001b[0;32m     14\u001b[0m     \u001b[38;5;66;03m# output = self.attention(output)\u001b[39;00m\n\u001b[0;32m     15\u001b[0m     output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfc(output\u001b[38;5;241m.\u001b[39mreshape([\u001b[38;5;241m1\u001b[39m,\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m]))\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\paddle\\nn\\layer\\layers.py:1530\u001b[0m, in \u001b[0;36mLayer.__call__\u001b[1;34m(self, *inputs, **kwargs)\u001b[0m\n\u001b[0;32m   1521\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39minputs: Any, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs: Any) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Any:\n\u001b[0;32m   1522\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[0;32m   1523\u001b[0m         (\u001b[38;5;129;01mnot\u001b[39;00m in_to_static_mode())\n\u001b[0;32m   1524\u001b[0m         \u001b[38;5;129;01mand\u001b[39;00m (\u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks)\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1528\u001b[0m         \u001b[38;5;129;01mand\u001b[39;00m (\u001b[38;5;129;01mnot\u001b[39;00m in_profiler_mode() \u001b[38;5;129;01mor\u001b[39;00m in_sot_simulation_mode())\n\u001b[0;32m   1529\u001b[0m     ):\n\u001b[1;32m-> 1530\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mforward(\u001b[38;5;241m*\u001b[39minputs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1531\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   1532\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dygraph_call_func(\u001b[38;5;241m*\u001b[39minputs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\paddle\\nn\\layer\\rnn.py:1825\u001b[0m, in \u001b[0;36mRNNBase.forward\u001b[1;34m(self, inputs, initial_states, sequence_length)\u001b[0m\n\u001b[0;32m   1813\u001b[0m     initial_states \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m   1814\u001b[0m         [initial_states]\n\u001b[0;32m   1815\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1818\u001b[0m         \u001b[38;5;28;01melse\u001b[39;00m initial_states\n\u001b[0;32m   1819\u001b[0m     )\n\u001b[0;32m   1821\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcould_use_cudnn \u001b[38;5;129;01mand\u001b[39;00m (\n\u001b[0;32m   1822\u001b[0m     \u001b[38;5;129;01mnot\u001b[39;00m paddle\u001b[38;5;241m.\u001b[39mdevice\u001b[38;5;241m.\u001b[39mis_compiled_with_rocm() \u001b[38;5;129;01mor\u001b[39;00m sequence_length \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1823\u001b[0m ):\n\u001b[0;32m   1824\u001b[0m     \u001b[38;5;66;03m# Add CPU kernel and dispatch in backend later\u001b[39;00m\n\u001b[1;32m-> 1825\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_cudnn_impl(inputs, initial_states, sequence_length)\n\u001b[0;32m   1827\u001b[0m states \u001b[38;5;241m=\u001b[39m split_states(\n\u001b[0;32m   1828\u001b[0m     initial_states, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnum_directions \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m2\u001b[39m, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstate_components\n\u001b[0;32m   1829\u001b[0m )\n\u001b[0;32m   1830\u001b[0m final_states \u001b[38;5;241m=\u001b[39m []\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\paddle\\nn\\layer\\rnn.py:1728\u001b[0m, in \u001b[0;36mRNNBase._cudnn_impl\u001b[1;34m(self, inputs, initial_states, sequence_length)\u001b[0m\n\u001b[0;32m   1721\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_cudnn_impl\u001b[39m(\n\u001b[0;32m   1722\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m   1723\u001b[0m     inputs: Tensor,\n\u001b[0;32m   1724\u001b[0m     initial_states: TensorOrTensors \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m   1725\u001b[0m     sequence_length: \u001b[38;5;28mint\u001b[39m \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m   1726\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28mtuple\u001b[39m[Tensor, Tensor \u001b[38;5;241m|\u001b[39m \u001b[38;5;28mtuple\u001b[39m[Tensor, Tensor]]:\n\u001b[0;32m   1727\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtime_major:\n\u001b[1;32m-> 1728\u001b[0m         inputs \u001b[38;5;241m=\u001b[39m paddle\u001b[38;5;241m.\u001b[39mtensor\u001b[38;5;241m.\u001b[39mtranspose(inputs, [\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m2\u001b[39m])\n\u001b[0;32m   1730\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m in_dynamic_or_pir_mode():\n\u001b[0;32m   1731\u001b[0m         out, _, state \u001b[38;5;241m=\u001b[39m _C_ops\u001b[38;5;241m.\u001b[39mrnn(\n\u001b[0;32m   1732\u001b[0m             inputs,\n\u001b[0;32m   1733\u001b[0m             initial_states,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1744\u001b[0m             \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtraining,\n\u001b[0;32m   1745\u001b[0m         )\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\paddle\\tensor\\linalg.py:127\u001b[0m, in \u001b[0;36mtranspose\u001b[1;34m(x, perm, name)\u001b[0m\n\u001b[0;32m     61\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m     62\u001b[0m \u001b[38;5;124;03mPermute the data dimensions of `input` according to `perm`.\u001b[39;00m\n\u001b[0;32m     63\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    124\u001b[0m \n\u001b[0;32m    125\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    126\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m in_dynamic_or_pir_mode():\n\u001b[1;32m--> 127\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m _C_ops\u001b[38;5;241m.\u001b[39mtranspose(x, perm)\n\u001b[0;32m    128\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    129\u001b[0m     check_variable_and_dtype(\n\u001b[0;32m    130\u001b[0m         x,\n\u001b[0;32m    131\u001b[0m         \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mx\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    149\u001b[0m         \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtranspose\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[0;32m    150\u001b[0m     )\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "\n",
    "#定义参数训练模型\n",
    "training_iters = 20000\n",
    "display_step = 100\n",
    "n_input = 20\n",
    "step = 0\n",
    "\n",
    "offset = random.randint(0,n_input+1)\n",
    "end_offset = n_input + 1\n",
    "\n",
    "while step < training_iters:\n",
    "    start_time = time.time()\n",
    "    # 随机取一个位置偏移\n",
    "    if offset > (len(training_data)-end_offset):\n",
    "        offset = random.randint(0, n_input+1)\n",
    "   \n",
    "    inwords =wordlabel[offset:offset+n_input]\n",
    "    inwords = np.reshape(np.array(inwords), [n_input, -1,  1])\n",
    "\n",
    "    out_onehot = wordlabel[offset+1:offset+n_input+1]\n",
    "\n",
    "\n",
    "    hidden = model.init_zero_state()\n",
    "    # print(hidden)\n",
    "    optimizer.clear_grad()\n",
    "\n",
    "    loss = 0.\n",
    "    inputs, targets = paddle.to_tensor(inwords), paddle.to_tensor(out_onehot)\n",
    "    for c in range(n_input):\n",
    "        outputs, hidden = model(inputs[c], hidden)\n",
    "        loss += F.cross_entropy(outputs, targets[c].reshape([1]))\n",
    "\n",
    "    loss /= n_input#求每个字的平均loss\n",
    "    loss.backward()\n",
    "\n",
    "    optimizer.step()\n",
    "\n",
    "    #输出日志\n",
    "    with paddle.set_grad_enabled(False):\n",
    "        if (step+1) % display_step == 0:\n",
    "            print(f'Time elapsed: {(time.time() - start_time)/60:.4f} min')\n",
    "            print(f'step {step+1} | Loss {loss.item():.2f}\\n\\n')\n",
    "            with paddle.no_grad():\n",
    "                print(evaluate(model, inputs, 32), '\\n')\n",
    "            print(50*'=')\n",
    "            paddle.save(model.state_dict(), 'model_state'+str(2)+'.pdparams')\n",
    "\n",
    "    step += 1\n",
    "    offset += (n_input+1)#中间隔了一个，作为预测\n",
    "\n",
    "print(\"Finished!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 运行代码"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "你的梦，激出片伸的心效。\n",
      "\n",
      "　　　　月我又来的花时，痴事伤，在么界一袭优埃了无微的笑逝，再那定而，静种着陌生。\n",
      "\n",
      "　　月默般，任终我着的海光，而须鸦的笑，恨份还有婉片，惹，年许年，激茗时，一只的雨的时，蝶抗同的时纯，湿有百下心。\n",
      "\n",
      "　　　月回美暖的结改，总一最起雨笑恨，句需我绽的声光，给百潮有着的奈，落冰法雨的雨，岁歌思，在头技惹人起往，么你都知者笺，执子的心暖，否诉作有后面，那相笑的迷的薄，有点总的目慷回时，回厚度过美墨Q刻的梦，任在你深彼的起，游的信候，习渐郁，吹泯，那心生时的声，波态会的线纱平而伤的歌目总而在字恍数是我的人个？\n",
      "\n",
      "　月用有花都押律的时光，试去忧展纯的扬，终新在一长的微笑痴，烦里的荡花们土的暖，悠声郁，让一当往的心，雨是了愿如开的\n",
      "　　能向伤的嫁格，激涌话到的天，多又如潮极，耳究不声望，否憔挣落过，熟遍出半视的雨边，仿由过的画声光，夕执望是涂场身却的香，滚\n",
      "该字我还没学会\n",
      "秋天的风起，耳春微觉阴到，押躇下你的扬，那技磕却适，带的明挣者绊，那滥起眸中的微盛促，雁媚的美。\n",
      "　　　　千的个而，铃具才往能涛奈，再以醒的微笑小没，有香的一意，恍翩句，不时。一勉毫，执想个心面；承遍古须的放，一份友灰轮，耳普面，不丽，耳以果望的画海却浪，我不文年速，肠睁当不的常，永试的边帜，一千放受坐是种走有着，耳份那改歌等再境，才你凝自份，掬想时深。又张悲心乡，一不迷的情绽，浅人心，我肠苦远的时忆，带如段你多证今你，而精红醒的歌宫经。种着月在我的时由，涛注红局花，成不面行这在什痛场般的河醉，静墨眸，虔不要着你以你优滥的面，请们年。在\n",
      "　　　　岁月度的眠，飘翩时，一痴慰，回看一然，用渐领而记的信悦，而被趋的首恢声，段在深此之间是命的几路前。\n",
      "\n",
      "　　月生歌千朵。也站的身缘，滚伤香世，今回这\n",
      "沐望忆的面弊上的律，低生和来起的究，熟着世旧天起，弹同你。\n",
      "\n",
      "　　月雨得百线，根在一个不花，我\n",
      "该字我还没学会\n",
      "该字我还没学会\n",
      "该字我还没学会\n",
      "该字我还没学会\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import paddle\n",
    "n_input =20 \n",
    "layer_state_dictm = paddle.load(\"model_state2.pdparams\")\n",
    "model.set_state_dict(layer_state_dictm)\n",
    "while True:\n",
    "    prompt = \"请输入几个字，最好是%s个: \" % n_input#因为训练我设置的句子长度为20，但是实际输入短一点又无所谓\n",
    "    sentence = input(prompt)\n",
    "    if sentence == \"break\":\n",
    "        break\n",
    "    inputword = sentence.strip()\n",
    "    \n",
    "    try:\n",
    "        inputword = get_ch_lable_v(None,word_num_map,inputword)\n",
    "        keys = np.reshape(np.array(inputword), [ len(inputword),-1, 1])\n",
    "        zi_num = 400\n",
    "        \n",
    "        model.eval()\n",
    "        with paddle.no_grad():\n",
    "            sentence =evaluate(model, paddle.to_tensor(keys), zi_num)# zi_num就代表后面继续模型输出字数 总共为n_input + zi_num\n",
    "\n",
    "        print(sentence)\n",
    "    # break\n",
    "    except:\n",
    "        print(\"该字我还没学会\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "几个例子：\n",
    ">1. 秋天的风:\n",
    "\n",
    ">秋天的风茫然，无须多问，无须追究，执子之手，我们注定天长地久。\n",
    "再不会为了一句话，而和人争得面红耳赤；再不会为了一句话，而和人争得到许，是你的美丽，落在我最暖的心海。而那灰色的头像却让我茫然和无奈，悲由心生，伤从何来？\n",
    "茫然的心境，遥远的梦幻，飘荡，游离恍Q上成过的人比比皆是。百年仅修得同渡船，要种多少善果才能与他擦肩而过的奔鹜，悲伤的那么？\n",
    "茫然的心境，遥远的梦幻，飘荡，游离恍若几个世纪的殷虹？也许，是你以来泪。\n",
    "再不会为了一句话，而和此消魂刻骨。\n",
    "每一天的早晨我们还是得用飞的圆刻，一行行眼泪的落下的瞬间，终湿透了写满思念的信笺，雁字回时路边，带上我深深地爱恋中，我愿为的是希望大家一起进步。虽然出于一片好的？许许多景，眼泪的渴望。轻轻拉开窗帘，一场春雨，淋湿了虔诚向往的花朵，许许多多的回忆片段如同雨浇开的花香，温馨着那深藏的梦，一如此刻的心境，任那悠悠飘荡的花香\n",
    "\n",
    "----\n",
    "\n",
    ">2.风的吹：\n",
    "\n",
    ">风的吹起，凝眸深处你的微笑惹人痴迷，无奈生命里伏伏起起，你的美永远刻在了最初的单纯，当岁月荒芜了似乎成熟的心田，文字是否仍可以承受很回；石桥上飘荡的魂灵，都舍得了前尘旧梦，断前因后果，忘尽一世浮沉得失，一生爱恨情仇。而我，千年华满天下就人生的方向，从痴痴地心。\n",
    "　　有时偏执于一己的看法，旁观者清，当局者迷，朋友善意的提点，点出事情的利弊，道出性格的缺陷，为的是希望大家一起进步。虽然出于一片好心，人普遍面皮薄，请配合先赞后弹等技巧，请配合先赞后弹等技巧，请辅以诚恳温和的态度，否则，忠言逆耳，成了反效果，破坏双方的关系。　　\n",
    "   每一天的早晨我们还是需要坚强，即使远离你无数日子，我依偎在三生石畔夜。\n",
    "　　再不会为了一句话，而和人争得面红耳赤；每心上的青面拼凑起。夕阳下你的美丽，落日的晚霞像是给你披上漂亮的嫁衣，习习微风把你的面纱吹起，凝眸深处你的微笑惹人痴迷，无奈生命里伏伏起起，你的美\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
