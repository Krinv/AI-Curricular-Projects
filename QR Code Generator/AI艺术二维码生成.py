# -*- coding: utf-8 -*-
"""Untitled2.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1h00oAeb_EFm-tHVTlaME_CUpQHMCYJeH
"""

# é€‚é…Colab T4 GPUçš„ç¯å¢ƒé…ç½®
!pip install -q torch>=2.1.0 torchvision torchaudio --index-url https://download.pytorch.org/whl/cu118
!pip install -q diffusers>=0.27.0 transformers>=4.38.0 accelerate>=0.27.0
!pip install -q qrcode>=7.4.2 Pillow>=10.2.0 requests>=2.31.0 gradio>=3.48.0
!pip install -q huggingface_hub>=0.21.0 xformers>=0.0.23  # xformersä¼˜åŒ–T4æ˜¾å­˜

# æ£€æŸ¥GPUé…ç½®
import torch
print(f"GPUå‹å·: {torch.cuda.get_device_name(0)}")
print(f"CUDAç‰ˆæœ¬: {torch.version.cuda}")

import os
import random
import json
import requests
from hashlib import md5
from PIL import Image
import qrcode
import torch
from gradio import (
    Blocks, Textbox, Image as GradioImage, Slider,
    Button, Examples, Checkbox, Accordion, Row, Column,
    Markdown, Gallery, Number
)
from diffusers import StableDiffusionControlNetPipeline, ControlNetModel, UniPCMultistepScheduler

# 1. å®‰è£…å¿…è¦ä¾èµ–ï¼ˆé¦–æ¬¡è¿è¡Œè‡ªåŠ¨å®‰è£…ï¼‰
!pip install -q torch>=2.1.0 diffusers>=0.27.0 transformers>=4.38.0 accelerate>=0.27.0
!pip install -q qrcode Pillow requests gradio xformers

# 2. è®¾å¤‡é…ç½®ï¼ˆå¼ºåˆ¶GPUåŠ é€Ÿï¼‰
device = "cuda" if torch.cuda.is_available() else "cpu"
if device != "cuda":
    raise RuntimeError("è¯·åœ¨Colabä¸­å¯ç”¨GPUï¼šä¿®æ”¹â†’ç¬”è®°æœ¬è®¾ç½®â†’ç¡¬ä»¶åŠ é€Ÿå™¨é€‰æ‹©T4 GPU")
dtype = torch.float16  # é€‚é…T4æ˜¾å­˜

# 3. åŠ è½½å…¬å¼€æ¨¡å‹ï¼ˆæ— éœ€ç™»å½•ï¼‰
controlnet = ControlNetModel.from_pretrained(
    "monster-labs/control_v1p_sd15_qrcode_monster",
    torch_dtype=dtype,
    use_safetensors=True
).to(device)

pipe = StableDiffusionControlNetPipeline.from_pretrained(
    "CompVis/stable-diffusion-v1-4",
    controlnet=controlnet,
    torch_dtype=dtype,
    safety_checker=None,
    use_safetensors=True
).to(device)

# ä¼˜åŒ–æ¨ç†é€Ÿåº¦
pipe.scheduler = UniPCMultistepScheduler.from_config(pipe.scheduler.config)
pipe.enable_xformers_memory_efficient_attention()  # T4 GPUåŠ é€Ÿ

# 4. å·¥å…·å‡½æ•°
def resize_for_condition_image(input_image: Image, resolution: int):
    input_image = input_image.convert("RGB")
    W, H = input_image.size
    k = resolution / min(H, W)
    H, W = int(round(H * k / 64) * 64), int(round(W * k / 64) * 64)
    return input_image.resize((W, H), Image.LANCZOS)

def translate(query):
    try:
        # ç™¾åº¦ç¿»è¯‘APIï¼ˆå¯é€‰ï¼Œå¤±è´¥ä¸å½±å“ï¼‰
        appid = '20241229002240718'
        appkey = 'UJ3uhuX_gzQV8LMwwVTf'
        from_lang = "zh"
        to_lang = "en"
        url = "http://api.fanyi.baidu.com/api/trans/vip/translate"

        salt = random.randint(32768, 65536)
        sign = md5(f"{appid}{query}{salt}{appkey}".encode()).hexdigest()
        payload = {
            "appid": appid, "q": query, "from": from_lang,
            "to": to_lang, "salt": salt, "sign": sign
        }
        r = requests.post(url, params=payload)
        return r.json()["trans_result"][0]["dst"]
    except:
        return query  # ç¿»è¯‘å¤±è´¥æ—¶è¿”å›åŸæç¤ºè¯

# 5. æ ¸å¿ƒç”Ÿæˆå‡½æ•°
def generate_qrcode(
    qr_content, prompt, negative_prompt,
    num_images, width, height, steps,
    guidance, control_strength, noise_strength,
    seed, eta, init_img, qr_img, use_qr_as_init
):
    if not prompt:
        raise ValueError("è¯·è¾“å…¥æç¤ºè¯ï¼")
    prompt_en = translate(prompt)

    # ç”Ÿæˆæˆ–å¤„ç†äºŒç»´ç 
    if not qr_img or (isinstance(qr_img, Image) and qr_img.size == (1, 1)):
        qr = qrcode.QRCode(
            version=1, error_correction=qrcode.ERROR_CORRECT_H,
            box_size=10, border=4
        )
        qr.add_data(qr_content)
        qr.make(fit=True)
        qr_img = qr.make_image(fill_color="black", back_color="white")

    qr_img = resize_for_condition_image(qr_img, min(width, height))
    init_img = qr_img if use_qr_as_init else init_img
    if init_img:
        init_img = resize_for_condition_image(init_img, min(width, height))

    # ç§å­å¤„ç†
    base_seed = random.randint(0, 10**18) if seed == -1 else seed

    # ç”Ÿæˆå¤šå¼ å›¾ç‰‡
    results = []
    for i in range(num_images):
        generator = torch.Generator(device).manual_seed(base_seed + i)
        with torch.no_grad():
            output = pipe(
                prompt=prompt_en,
                negative_prompt=negative_prompt,
                image=qr_img,
                generator=generator,
                width=width,
                height=height,
                guidance_scale=guidance,
                controlnet_conditioning_scale=control_strength,
                eta=eta,
                num_inference_steps=steps,
                strength=noise_strength,
                init_image=init_img if init_img else None
            )
        results.append(output.images[0])

    return prompt_en, results

# 6. æ„å»ºç½‘é¡µç•Œé¢
with Blocks(title="AIè‰ºæœ¯äºŒç»´ç ç”Ÿæˆå™¨") as demo:
    Markdown("""
    # ğŸ¨ AIè‰ºæœ¯äºŒç»´ç ç”Ÿæˆå™¨
    ### ç‚¹å‡»ä¸‹æ–¹é“¾æ¥è¿›å…¥ç½‘é¡µæ“ä½œï¼Œæ”¯æŒï¼š
    - è‡ªå®šä¹‰äºŒç»´ç å†…å®¹ä¸è‰ºæœ¯é£æ ¼
    - è°ƒèŠ‚å‚æ•°æ§åˆ¶ç”Ÿæˆæ•ˆæœ
    - ä¸€æ¬¡ç”Ÿæˆå¤šå¼ å›¾ç‰‡å¯¹æ¯”
    """)

    with Row():
        # å·¦ä¾§ï¼šå‚æ•°è®¾ç½®åŒº
        with Column(scale=1):
            # äºŒç»´ç å†…å®¹
            Markdown("#### 1. äºŒç»´ç å†…å®¹ï¼ˆå¿…å¡«ï¼‰")
            qr_content = Textbox(
                label="è¾“å…¥ç½‘å€æˆ–æ–‡æœ¬",
                placeholder="ä¾‹å¦‚ï¼šhttps://www.example.com"
            )

            # å›¾åƒè®¾ç½®
            with Accordion("2. å›¾åƒä¸åˆå§‹è®¾ç½®", open=True):
                Markdown("å¯ä¸Šä¼ è‡ªå®šä¹‰äºŒç»´ç ï¼ˆä¸ä¸Šä¼ åˆ™è‡ªåŠ¨ç”Ÿæˆï¼‰")
                qr_img = GradioImage(type="pil", label="è‡ªå®šä¹‰äºŒç»´ç ")
                use_qr_as_init = Checkbox(True, label="ç”¨äºŒç»´ç ä½œä¸ºåˆå§‹å›¾åƒ")
                init_img = GradioImage(type="pil", label="è‡ªå®šä¹‰åˆå§‹å›¾åƒ", visible=False)

                # åŠ¨æ€æ˜¾ç¤ºåˆå§‹å›¾åƒä¸Šä¼ æ¡†
                def toggle_init(checked):
                    return gr.update(visible=not checked)
                use_qr_as_init.change(toggle_init, use_qr_as_init, init_img)

            # æç¤ºè¯
            with Accordion("3. æç¤ºè¯è®¾ç½®", open=True):
                Markdown("æè¿°è‰ºæœ¯é£æ ¼ï¼ˆä¾‹å¦‚ï¼šã€Œæ˜Ÿç©ºä¸‹çš„æµ·æ´‹ï¼Œæ¢µé«˜é£æ ¼ã€ï¼‰")
                prompt = Textbox(label="ä¸­æ–‡æç¤ºè¯")
                prompt_en = Textbox(label="è‹±æ–‡æç¤ºè¯ï¼ˆè‡ªåŠ¨ç¿»è¯‘ï¼‰", interactive=False)
                Markdown("éœ€è¦é¿å…çš„å†…å®¹ï¼ˆå¦‚æ¨¡ç³Šã€ä½è´¨é‡ï¼‰")
                negative_prompt = Textbox(
                    label="è´Ÿé¢æç¤ºè¯",
                    value="ugly, blurry, low quality, nsfw, text"
                )

            # ç”Ÿæˆå‚æ•°
            with Accordion("4. é«˜çº§å‚æ•°è°ƒèŠ‚", open=True):
                num_images = Slider(1, 4, 1, 1, label="ç”Ÿæˆæ•°é‡")
                width = Slider(512, 1024, 768, 64, label="å®½åº¦ï¼ˆ64å€æ•°ï¼‰")
                height = Slider(512, 1024, 768, 64, label="é«˜åº¦ï¼ˆ64å€æ•°ï¼‰")
                steps = Slider(20, 80, 40, 5, label="æ¨ç†æ­¥æ•°")

                guidance = Slider(1, 20, 7.5, 0.5, label="æç¤ºè¯æƒé‡")
                control_strength = Slider(0.5, 3, 1.2, 0.1, label="æ§åˆ¶ç½‘å¼ºåº¦ï¼ˆè¶Šé«˜äºŒç»´ç è¶Šæ¸…æ™°ï¼‰")
                noise_strength = Slider(0.7, 1.0, 0.9, 0.01, label="å™ªå£°å¼ºåº¦ï¼ˆè¶Šé«˜è‰ºæœ¯æ„Ÿè¶Šå¼ºï¼‰")

                eta = Number(0.0, label="é‡‡æ ·éšæœºæ€§ï¼ˆ0ä¸ºç¡®å®šï¼‰")
                seed = Slider(-1, 10**18, -1, 1, label="ç§å­ï¼ˆ-1ä¸ºéšæœºï¼‰", randomize=True)

            # ç”ŸæˆæŒ‰é’®
            generate_btn = Button("ğŸš€ ç”Ÿæˆè‰ºæœ¯äºŒç»´ç ", variant="primary", size="lg")

        # å³ä¾§ï¼šç»“æœå±•ç¤ºåŒº
        with Column(scale=1):
            Markdown("### ç”Ÿæˆç»“æœï¼ˆç‚¹å‡»å¯ä¸‹è½½ï¼‰")
            result_gallery = Gallery(
                label="è‰ºæœ¯äºŒç»´ç ",
                columns=2,
                rows=2,
                object_fit="contain",
                height="auto"
            )

    # ç»‘å®šç”Ÿæˆäº‹ä»¶
    generate_btn.click(
        fn=generate_qrcode,
        inputs=[
            qr_content, prompt, negative_prompt,
            num_images, width, height, steps,
            guidance, control_strength, noise_strength,
            seed, eta, init_img, qr_img, use_qr_as_init
        ],
        outputs=[prompt_en, result_gallery]
    )

    # ç¤ºä¾‹å‚è€ƒ
    with Accordion("ğŸ“Œ ç¤ºä¾‹ï¼ˆç‚¹å‡»å¯ç›´æ¥ä½¿ç”¨ï¼‰", open=False):
        Examples(
            examples=[
                [
                    "https://colab.research.google.com/",
                    "èµ›åšæœ‹å…‹åŸå¸‚ï¼Œéœ“è™¹ç¯å…‰ï¼Œé›¨å¤œï¼Œé«˜æ¥¼",
                    "ugly, blurry",
                    2, 768, 768, 40, 7.5, 1.3, 0.9, -1, 0.0, None, None, True
                ],
                [
                    "https://github.com/",
                    "è«å¥ˆé£æ ¼ç¡è²ï¼Œå°è±¡æ´¾ï¼Œå…‰å½±ï¼Œæ°´é¢",
                    "ugly, blurry",
                    2, 768, 768, 50, 8.0, 1.1, 0.85, -1, 0.0, None, None, True
                ]
            ],
            inputs=[
                qr_content, prompt, negative_prompt,
                num_images, width, height, steps,
                guidance, control_strength, noise_strength,
                seed, eta, init_img, qr_img, use_qr_as_init
            ],
            outputs=[prompt_en, result_gallery]
        )

# 7. å¯åŠ¨ç½‘é¡µæœåŠ¡ï¼ˆç”Ÿæˆå¯ç‚¹å‡»é“¾æ¥ï¼‰
demo.queue(max_size=10).launch(
    share=True,  # ç”Ÿæˆå…¬å¼€å¯è®¿é—®çš„ä¸´æ—¶é“¾æ¥
    debug=False,
    server_name="0.0.0.0"
)

