{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "initial_id",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/environment/miniconda3/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n"
     ]
    }
   ],
   "source": [
    "# ===================================================================\n",
    "# Part 1: 设置与导入\n",
    "# ===================================================================\n",
    "import torch\n",
    "import torchvision\n",
    "import torchvision.models as models\n",
    "import torchvision.transforms as transforms\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, random_split\n",
    "from torch.optim.lr_scheduler import ReduceLROnPlateau\n",
    "import os\n",
    "from PIL import Image\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "import datetime\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "from torchvision.transforms.autoaugment import AutoAugment, AutoAugmentPolicy\n",
    "import timm\n",
    "\n",
    "print(\"1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5b5f0c93b0b53a1b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "使用的设备: cuda, 正在配置模型: ConvNeXt-XL\n"
     ]
    }
   ],
   "source": [
    "# --- 核心配置区 ---\n",
    "MODEL_CONFIG = {\n",
    "    'model_name': 'ConvNeXt-XL', # <--- 目标模型: ConvNeXt-Large\n",
    "    'batch_size': 16,      # ConvNeXt-L模型很大，建议从较小的batch_size开始，如16或24\n",
    "    'learning_rate': 1e-4,\n",
    "    'num_epochs':30,\n",
    "    'warmup_epochs':5,\n",
    "}\n",
    "\n",
    "# 基本设置\n",
    "student_id = '22211360121'\n",
    "subdir = ''\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"使用的设备: {device}, 正在配置模型: {MODEL_CONFIG['model_name']}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5c6ff636",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- 正在为 ConvNeXt-XL 准备数据和变换 ---\n",
      "ConvNeXt-XL 官方推荐的预处理流程:\n",
      "Compose(\n",
      "    Resize(size=384, interpolation=bilinear, max_size=None, antialias=True)\n",
      "    CenterCrop(size=(384, 384))\n",
      "    ToTensor()\n",
      "    Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
      ")\n",
      "\n",
      "训练集大小: 3199, 验证集大小: 356\n"
     ]
    }
   ],
   "source": [
    "# ===================================================================\n",
    "# Part 2: 训练 ConvNeXt-Large 模型\n",
    "# ===================================================================\n",
    "\n",
    "# --- 2.1 数据预处理 ---\n",
    "print(f\"\\n--- 正在为 {MODEL_CONFIG['model_name']} 准备数据和变换 ---\")\n",
    "\n",
    "# 使用 timm 提供的标准预处理\n",
    "model_official_transforms = transforms.Compose([\n",
    "    transforms.Resize(384),\n",
    "    transforms.CenterCrop(384),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
    "                         std=[0.229, 0.224, 0.225])\n",
    "])\n",
    "print(f\"{MODEL_CONFIG['model_name']} 官方推荐的预处理流程:\")\n",
    "print(model_official_transforms)\n",
    "\n",
    "# 定义包含高级数据增强的训练集变换\n",
    "train_transform = transforms.Compose([\n",
    "    transforms.Resize(384),\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    AutoAugment(policy=AutoAugmentPolicy.IMAGENET),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
    "                         std=[0.229, 0.224, 0.225]),\n",
    "    transforms.RandomErasing(p=0.6, scale=(0.02, 0.33)),\n",
    "])\n",
    "# 验证集和测试集使用官方标准变换\n",
    "val_test_transform = model_official_transforms\n",
    "\n",
    "# --- 2.2 数据加载 ---\n",
    "full_train_dataset = torchvision.datasets.ImageFolder(root='new data/train')\n",
    "train_size = int(0.9 * len(full_train_dataset))\n",
    "val_size = len(full_train_dataset) - train_size\n",
    "train_subset, val_subset = random_split(full_train_dataset, [train_size, val_size], generator=torch.Generator().manual_seed(42))\n",
    "train_subset.dataset.transform = train_transform\n",
    "val_subset.dataset.transform = val_test_transform\n",
    "train_loader = DataLoader(train_subset, batch_size=MODEL_CONFIG['batch_size'], shuffle=True, num_workers=8, pin_memory=True)\n",
    "val_loader = DataLoader(val_subset, batch_size=MODEL_CONFIG['batch_size'], shuffle=False, num_workers=8, pin_memory=True)\n",
    "class_names = full_train_dataset.classes\n",
    "print(f\"\\n训练集大小: {len(train_subset)}, 验证集大小: {len(val_subset)}\")\n",
    "\n",
    "\n",
    "# --- 2.3 模型定义、优化器与调度器 ---\n",
    "# 使用 timm 加载 ConvNeXt-XL 模型（预训练）\n",
    "model = timm.create_model('convnext_xlarge', pretrained=True)\n",
    "# 替换最后的分类头\n",
    "num_ftrs = model.head.in_features\n",
    "model.head.fc= nn.Linear(num_ftrs, len(class_names))\n",
    "model.to(device)\n",
    "\n",
    "class FocalLossWithSmoothing(nn.Module):\n",
    "    def __init__(self, alpha=1, gamma=2, smoothing=0.1):\n",
    "        super().__init__()\n",
    "        self.alpha = alpha\n",
    "        self.gamma = gamma\n",
    "        self.smoothing = smoothing\n",
    "\n",
    "    def forward(self, input, target):\n",
    "        log_probs = nn.functional.log_softmax(input, dim=-1)\n",
    "        probs = torch.exp(log_probs)\n",
    "        nll_loss = -log_probs.gather(dim=-1, index=target.unsqueeze(1)).squeeze(1)\n",
    "        focal_weight = (1 - probs.gather(dim=-1, index=target.unsqueeze(1)).squeeze(1)) ** self.gamma\n",
    "        loss = self.alpha * focal_weight * nll_loss\n",
    "        return loss.mean()\n",
    "\n",
    "criterion = FocalLossWithSmoothing()\n",
    "\n",
    "\n",
    "optimizer = optim.AdamW(model.parameters(), lr=MODEL_CONFIG['learning_rate'], weight_decay=0.01)\n",
    "\n",
    "from torch.optim.lr_scheduler import CosineAnnealingWarmRestarts\n",
    "scheduler = CosineAnnealingWarmRestarts(optimizer, T_0=5, T_mult=2)\n",
    "\n",
    "# 初始化AMP梯度缩放器\n",
    "scaler = torch.cuda.amp.GradScaler()\n",
    "\n",
    "\n",
    "# --- 2.4 训练与验证循环 (集成AMP) ---\n",
    "model_save_path = f\"f4.pth\" # <--- 修改保存路径\n",
    "best_val_loss = float('inf')\n",
    "epochs_no_improve = 0\n",
    "early_stop_patience = 7\n",
    "train_loss_history, val_loss_history, val_acc_history = [], [], []\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4b591a843b0b9b0c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- 开始为 ConvNeXt-XL 进行实际训练 ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "训练轮次 1/30: 100%|██████████| 200/200 [00:49<00:00,  4.02it/s, loss=0.0958, lr=1.0e-04]\n",
      "验证轮次 1/30: 100%|██████████| 23/23 [00:01<00:00, 11.76it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "轮次 1 | 训练损失: 1.4244 | 验证损失: 0.2824 | 验证准确率: 0.8904\n",
      "验证损失下降。保存最佳模型到 f4.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "训练轮次 2/30: 100%|██████████| 200/200 [00:49<00:00,  4.04it/s, loss=0.1828, lr=9.9e-05]\n",
      "验证轮次 2/30: 100%|██████████| 23/23 [00:01<00:00, 11.89it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "轮次 2 | 训练损失: 0.1218 | 验证损失: 0.2285 | 验证准确率: 0.8933\n",
      "验证损失下降。保存最佳模型到 f4.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "训练轮次 3/30: 100%|██████████| 200/200 [00:49<00:00,  4.04it/s, loss=0.0031, lr=9.9e-05]\n",
      "验证轮次 3/30: 100%|██████████| 23/23 [00:01<00:00, 11.88it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "轮次 3 | 训练损失: 0.0221 | 验证损失: 0.1690 | 验证准确率: 0.9213\n",
      "验证损失下降。保存最佳模型到 f4.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "训练轮次 4/30: 100%|██████████| 200/200 [00:49<00:00,  4.05it/s, loss=0.0009, lr=1.0e-04]\n",
      "验证轮次 4/30: 100%|██████████| 23/23 [00:01<00:00, 11.93it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "轮次 4 | 训练损失: 0.0025 | 验证损失: 0.1649 | 验证准确率: 0.9298\n",
      "验证损失下降。保存最佳模型到 f4.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "训练轮次 5/30: 100%|██████████| 200/200 [00:49<00:00,  4.05it/s, loss=0.0004, lr=1.0e-04]\n",
      "验证轮次 5/30: 100%|██████████| 23/23 [00:01<00:00, 11.84it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "轮次 5 | 训练损失: 0.0006 | 验证损失: 0.1618 | 验证准确率: 0.9382\n",
      "验证损失下降。保存最佳模型到 f4.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "训练轮次 6/30: 100%|██████████| 200/200 [00:49<00:00,  4.05it/s, loss=0.0004, lr=1.0e-04]\n",
      "验证轮次 6/30: 100%|██████████| 23/23 [00:01<00:00, 11.93it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "轮次 6 | 训练损失: 0.0003 | 验证损失: 0.1616 | 验证准确率: 0.9382\n",
      "验证损失下降。保存最佳模型到 f4.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "训练轮次 7/30: 100%|██████████| 200/200 [00:49<00:00,  4.05it/s, loss=0.0003, lr=1.0e-04]\n",
      "验证轮次 7/30: 100%|██████████| 23/23 [00:01<00:00, 12.48it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "轮次 7 | 训练损失: 0.0002 | 验证损失: 0.1619 | 验证准确率: 0.9354\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "训练轮次 8/30: 100%|██████████| 200/200 [00:49<00:00,  4.04it/s, loss=0.0002, lr=1.0e-04]\n",
      "验证轮次 8/30: 100%|██████████| 23/23 [00:01<00:00, 11.70it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "轮次 8 | 训练损失: 0.0002 | 验证损失: 0.1620 | 验证准确率: 0.9354\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "训练轮次 9/30: 100%|██████████| 200/200 [00:49<00:00,  4.06it/s, loss=0.0002, lr=1.0e-04]\n",
      "验证轮次 9/30: 100%|██████████| 23/23 [00:01<00:00, 12.41it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "轮次 9 | 训练损失: 0.0001 | 验证损失: 0.1626 | 验证准确率: 0.9382\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "训练轮次 10/30: 100%|██████████| 200/200 [00:49<00:00,  4.05it/s, loss=0.0001, lr=1.0e-04]\n",
      "验证轮次 10/30: 100%|██████████| 23/23 [00:01<00:00, 12.20it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "轮次 10 | 训练损失: 0.0001 | 验证损失: 0.1634 | 验证准确率: 0.9382\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "训练轮次 11/30: 100%|██████████| 200/200 [00:49<00:00,  4.04it/s, loss=0.0001, lr=1.0e-04]\n",
      "验证轮次 11/30: 100%|██████████| 23/23 [00:01<00:00, 11.87it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "轮次 11 | 训练损失: 0.0001 | 验证损失: 0.1640 | 验证准确率: 0.9354\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "训练轮次 12/30: 100%|██████████| 200/200 [00:49<00:00,  4.05it/s, loss=0.0001, lr=1.0e-04]\n",
      "验证轮次 12/30: 100%|██████████| 23/23 [00:01<00:00, 11.66it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "轮次 12 | 训练损失: 0.0001 | 验证损失: 0.1644 | 验证准确率: 0.9382\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "训练轮次 13/30: 100%|██████████| 200/200 [00:49<00:00,  4.04it/s, loss=0.0001, lr=1.0e-04]\n",
      "验证轮次 13/30: 100%|██████████| 23/23 [00:01<00:00, 11.86it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "轮次 13 | 训练损失: 0.0001 | 验证损失: 0.1649 | 验证准确率: 0.9382\n",
      "在 13 轮后触发早停机制。\n",
      "\n",
      "--- ConvNeXt-XL 训练完成！权重已保存至 f4.pth ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "print(f\"\\n--- 开始为 {MODEL_CONFIG['model_name']} 进行实际训练 ---\")\n",
    "\n",
    "for epoch in range(MODEL_CONFIG['num_epochs']):\n",
    "    model.train()\n",
    "    total_train_loss = 0\n",
    "    train_bar = tqdm(train_loader, desc=f'训练轮次 {epoch+1}/{MODEL_CONFIG[\"num_epochs\"]}')\n",
    "    for inputs, labels in train_bar:\n",
    "        inputs, labels = inputs.to(device), labels.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        with torch.cuda.amp.autocast():\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "        \n",
    "        scaler.scale(loss).backward()\n",
    "        scaler.step(optimizer)\n",
    "        scaler.update()\n",
    "\n",
    "        total_train_loss += loss.item()\n",
    "        train_bar.set_postfix({'loss': f'{loss.item():.4f}', 'lr': f'{optimizer.param_groups[0][\"lr\"]:.1e}'})\n",
    "    avg_train_loss = total_train_loss / len(train_loader)\n",
    "    train_loss_history.append(avg_train_loss)\n",
    "\n",
    "    model.eval()\n",
    "    total_val_loss, total_val_correct = 0, 0\n",
    "    with torch.no_grad():\n",
    "        val_bar = tqdm(val_loader, desc=f'验证轮次 {epoch+1}/{MODEL_CONFIG[\"num_epochs\"]}')\n",
    "        for inputs, labels in val_bar:\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "            with torch.cuda.amp.autocast():\n",
    "                outputs = model(inputs)\n",
    "                loss = criterion(outputs, labels)\n",
    "            total_val_loss += loss.item()\n",
    "            _, predicted = torch.max(outputs, 1)\n",
    "            total_val_correct += (predicted == labels).sum().item()\n",
    "    \n",
    "    avg_val_loss = total_val_loss / len(val_loader)\n",
    "    val_accuracy = total_val_correct / len(val_loader.dataset)\n",
    "    val_loss_history.append(avg_val_loss)\n",
    "    val_acc_history.append(val_accuracy)\n",
    "    \n",
    "    print(f'\\n轮次 {epoch+1} | 训练损失: {avg_train_loss:.4f} | 验证损失: {avg_val_loss:.4f} | 验证准确率: {val_accuracy:.4f}')\n",
    "    scheduler.step(avg_val_loss)\n",
    "\n",
    "    if avg_val_loss < best_val_loss:\n",
    "        best_val_loss = avg_val_loss\n",
    "        torch.save(model.state_dict(), model_save_path)\n",
    "        print(f'验证损失下降。保存最佳模型到 {model_save_path}')\n",
    "        epochs_no_improve = 0\n",
    "    else:\n",
    "        epochs_no_improve += 1\n",
    "    \n",
    "    if epochs_no_improve >= early_stop_patience:\n",
    "        print(f'在 {epoch+1} 轮后触发早停机制。')\n",
    "        break\n",
    "\n",
    "print(f\"\\n--- {MODEL_CONFIG['model_name']} 训练完成！权重已保存至 {model_save_path} ---\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "447509e55acea0aa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- 开始使用 ConvNeXt-XL 最佳模型进行预测 ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "使用 ConvNeXt-XL 和 TTA 进行预测:  25%|██▍       | 310/1244 [00:10<00:32, 28.47it/s]"
     ]
    }
   ],
   "source": [
    "# ===================================================================\n",
    "# Part 3: 预测与可视化\n",
    "# ===================================================================\n",
    "print(f\"\\n--- 开始使用 {MODEL_CONFIG['model_name']} 最佳模型进行预测 ---\")\n",
    "\n",
    "# --- 3.1 加载模型 ---\n",
    "# 创建一个与保存的模型结构相同的空模型\n",
    "# 创建一个空模型，并修改结构\n",
    "model = timm.create_model('convnext_xlarge', pretrained=False)\n",
    "num_ftrs = model.head.fc.in_features\n",
    "model.head.fc = nn.Linear(num_ftrs, len(class_names))\n",
    "\n",
    "# 加载权重\n",
    "model.load_state_dict(torch.load(model_save_path))\n",
    "model.to(device)\n",
    "model.eval()\n",
    "\n",
    "# --- 3.2 预测 (带TTA) ---\n",
    "transform = val_test_transform # 使用标准的验证/测试变换\n",
    "test_folder = 'new data/testB'\n",
    "test_images = [img for img in os.listdir(test_folder) if img.endswith('.jpg')]\n",
    "predicts = []\n",
    "idx = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for img_name in tqdm(test_images, desc=f'使用 {MODEL_CONFIG[\"model_name\"]} 和 TTA 进行预测'):\n",
    "        img_path = os.path.join(test_folder, img_name)\n",
    "        image = Image.open(img_path).convert('RGB')\n",
    "        \n",
    "        images_tta = [\n",
    "            transform(image),\n",
    "            transform(transforms.functional.hflip(image)),\n",
    "            transform(transforms.functional.rotate(image, 15)),\n",
    "            transform(transforms.functional.rotate(image, -15))\n",
    "        ]\n",
    "        batch_tta = torch.stack(images_tta).to(device)\n",
    "        \n",
    "        with torch.cuda.amp.autocast():\n",
    "             outputs_tta = model(batch_tta)\n",
    "\n",
    "        probs_tta = torch.softmax(outputs_tta, dim=1)\n",
    "        avg_probs = torch.mean(probs_tta, dim=0)\n",
    "        _, predicted = torch.max(avg_probs, 0)\n",
    "        \n",
    "        predicts.append(predicted.item())\n",
    "        idx.append(img_name.replace('.jpg', ''))\n",
    "\n",
    "# --- 3.3 保存结果 ---\n",
    "submission = pd.DataFrame({'id': idx, 'label': predicts})\n",
    "submission['id'] = submission['id'].astype(int)\n",
    "submission = submission.sort_values(by='id')\n",
    "submission_filename = f\"{student_id}_submission_{datetime.datetime.now().strftime('%Y%m%d_%H%M%S')}.csv\"\n",
    "submission.to_csv(submission_filename, index=False)\n",
    "print(f\"预测完成，结果已保存到 {submission_filename}！\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f2ff69a-78f3-4974-ac9b-266397dfd51f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- 3.4 可视化 ---\n",
    "print(\"\\n--- 开始生成可视化图表 ---\")\n",
    "num_actual_epochs = len(train_loss_history)\n",
    "plt.style.use('seaborn-v0_8-whitegrid')\n",
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(18, 6))\n",
    "\n",
    "ax1.plot(range(1, num_actual_epochs + 1), train_loss_history, 'o-', label='训练损失 (Training Loss)')\n",
    "ax1.plot(range(1, num_actual_epochs + 1), val_loss_history, 'o-', label='验证损失 (Validation Loss)')\n",
    "ax1.set_title('训练与验证损失曲线 (ConvNeXt-Large)', fontsize=16)\n",
    "ax1.legend()\n",
    "\n",
    "ax2.plot(range(1, num_actual_epochs + 1), val_acc_history, 'o-', label='验证准确率 (Validation Accuracy)', color='g')\n",
    "ax2.set_title('验证准确率曲线 (ConvNeXt-Large)', fontsize=16)\n",
    "ax2.legend()\n",
    "\n",
    "plt.suptitle('ConvNeXt-Large 训练过程监控', fontsize=20)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fab37e64-d583-40ca-b0fd-9e00ea435aff",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
