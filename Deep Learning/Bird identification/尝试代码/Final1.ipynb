{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "initial_id",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ===================================================================\n",
    "# Part 1: 设置与导入\n",
    "# ===================================================================\n",
    "import torch\n",
    "import torchvision\n",
    "import torchvision.models as models\n",
    "import torchvision.transforms as transforms\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, random_split\n",
    "from torch.optim.lr_scheduler import ReduceLROnPlateau\n",
    "import os\n",
    "from PIL import Image\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "import datetime\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "from torchvision.transforms.autoaugment import AutoAugment, AutoAugmentPolicy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5b5f0c93b0b53a1b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "使用的设备: cuda, 正在配置模型: ConvNeXt-L\n"
     ]
    }
   ],
   "source": [
    "# --- 核心配置区 ---\n",
    "MODEL_CONFIG = {\n",
    "    'model_name': 'ConvNeXt-L', # <--- 目标模型: ConvNeXt-Large\n",
    "    'batch_size': 16,      # ConvNeXt-L模型很大，建议从较小的batch_size开始，如16或24\n",
    "    'learning_rate': 1e-4,\n",
    "    'num_epochs':30,\n",
    "    'warmup_epochs':5,\n",
    "}\n",
    "\n",
    "# 基本设置\n",
    "student_id = '22211360121'\n",
    "subdir = ''\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"使用的设备: {device}, 正在配置模型: {MODEL_CONFIG['model_name']}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5c6ff636",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- 正在为 ConvNeXt-L 准备数据和变换 ---\n",
      "ConvNeXt-L 官方推荐的预处理流程:\n",
      "ImageClassification(\n",
      "    crop_size=[224]\n",
      "    resize_size=[232]\n",
      "    mean=[0.485, 0.456, 0.406]\n",
      "    std=[0.229, 0.224, 0.225]\n",
      "    interpolation=InterpolationMode.BILINEAR\n",
      ")\n",
      "\n",
      "训练集大小: 3199, 验证集大小: 356\n"
     ]
    }
   ],
   "source": [
    "# ===================================================================\n",
    "# Part 2: 训练 ConvNeXt-Large 模型\n",
    "# ===================================================================\n",
    "\n",
    "# --- 2.1 数据预处理 ---\n",
    "print(f\"\\n--- 正在为 {MODEL_CONFIG['model_name']} 准备数据和变换 ---\")\n",
    "# 加载 ConvNeXt-Large 的官方预训练权重\n",
    "weights = models.ConvNeXt_Large_Weights.DEFAULT # <--- 关键修改\n",
    "model_official_transforms = weights.transforms()\n",
    "print(f\"{MODEL_CONFIG['model_name']} 官方推荐的预处理流程:\")\n",
    "print(model_official_transforms)\n",
    "\n",
    "# 定义包含高级数据增强的训练集变换\n",
    "train_transform = transforms.Compose([\n",
    "    transforms.RandomResizedCrop(model_official_transforms.crop_size[0], scale=(0.5, 1.0)),\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    AutoAugment(policy=AutoAugmentPolicy.IMAGENET),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=model_official_transforms.mean, std=model_official_transforms.std),\n",
    "    transforms.RandomErasing(p=0.6, scale=(0.02, 0.33)),\n",
    "])\n",
    "# 验证集和测试集使用官方标准变换\n",
    "val_test_transform = model_official_transforms\n",
    "\n",
    "# --- 2.2 数据加载 ---\n",
    "full_train_dataset = torchvision.datasets.ImageFolder(root='new data/train')\n",
    "train_size = int(0.9 * len(full_train_dataset))\n",
    "val_size = len(full_train_dataset) - train_size\n",
    "train_subset, val_subset = random_split(full_train_dataset, [train_size, val_size], generator=torch.Generator().manual_seed(42))\n",
    "train_subset.dataset.transform = train_transform\n",
    "val_subset.dataset.transform = val_test_transform\n",
    "train_loader = DataLoader(train_subset, batch_size=MODEL_CONFIG['batch_size'], shuffle=True, num_workers=8, pin_memory=True)\n",
    "val_loader = DataLoader(val_subset, batch_size=MODEL_CONFIG['batch_size'], shuffle=False, num_workers=8, pin_memory=True)\n",
    "class_names = full_train_dataset.classes\n",
    "print(f\"\\n训练集大小: {len(train_subset)}, 验证集大小: {len(val_subset)}\")\n",
    "\n",
    "\n",
    "# --- 2.3 模型定义、优化器与调度器 ---\n",
    "# 加载预训练的 ConvNeXt-Large 模型\n",
    "model = models.convnext_large(weights=weights) # <--- 关键修改\n",
    "\n",
    "# 替换分类头以适应我们的任务\n",
    "num_ftrs = model.classifier[2].in_features\n",
    "model.classifier[2] = nn.Linear(num_ftrs, len(class_names))\n",
    "\n",
    "model.to(device)\n",
    "\n",
    "class FocalLossWithSmoothing(nn.Module):\n",
    "    def __init__(self, alpha=1, gamma=2, smoothing=0.1):\n",
    "        super().__init__()\n",
    "        self.alpha = alpha\n",
    "        self.gamma = gamma\n",
    "        self.smoothing = smoothing\n",
    "\n",
    "    def forward(self, input, target):\n",
    "        log_probs = nn.functional.log_softmax(input, dim=-1)\n",
    "        probs = torch.exp(log_probs)\n",
    "        nll_loss = -log_probs.gather(dim=-1, index=target.unsqueeze(1)).squeeze(1)\n",
    "        focal_weight = (1 - probs.gather(dim=-1, index=target.unsqueeze(1)).squeeze(1)) ** self.gamma\n",
    "        loss = self.alpha * focal_weight * nll_loss\n",
    "        return loss.mean()\n",
    "\n",
    "criterion = FocalLossWithSmoothing()\n",
    "\n",
    "\n",
    "optimizer = optim.AdamW(model.parameters(), lr=MODEL_CONFIG['learning_rate'], weight_decay=0.01)\n",
    "\n",
    "from torch.optim.lr_scheduler import CosineAnnealingWarmRestarts\n",
    "scheduler = CosineAnnealingWarmRestarts(optimizer, T_0=5, T_mult=2)\n",
    "\n",
    "# 初始化AMP梯度缩放器\n",
    "scaler = torch.cuda.amp.GradScaler()\n",
    "\n",
    "\n",
    "# --- 2.4 训练与验证循环 (集成AMP) ---\n",
    "model_save_path = f\"bird_classification_convnext_l_best.pth\" # <--- 修改保存路径\n",
    "best_val_loss = float('inf')\n",
    "epochs_no_improve = 0\n",
    "early_stop_patience = 7\n",
    "train_loss_history, val_loss_history, val_acc_history = [], [], []\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4b591a843b0b9b0c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- 开始为 ConvNeXt-L 进行实际训练 ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "训练轮次 1/30:  24%|██▍       | 48/200 [00:04<00:13, 10.89it/s, loss=4.1622, lr=1.0e-04]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[4], line 15\u001b[0m\n\u001b[1;32m     12\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m model(inputs)\n\u001b[1;32m     13\u001b[0m     loss \u001b[38;5;241m=\u001b[39m criterion(outputs, labels)\n\u001b[0;32m---> 15\u001b[0m \u001b[43mscaler\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mscale\u001b[49m\u001b[43m(\u001b[49m\u001b[43mloss\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     16\u001b[0m scaler\u001b[38;5;241m.\u001b[39mstep(optimizer)\n\u001b[1;32m     17\u001b[0m scaler\u001b[38;5;241m.\u001b[39mupdate()\n",
      "File \u001b[0;32m/environment/miniconda3/lib/python3.11/site-packages/torch/_tensor.py:522\u001b[0m, in \u001b[0;36mTensor.backward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    512\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m has_torch_function_unary(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    513\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(\n\u001b[1;32m    514\u001b[0m         Tensor\u001b[38;5;241m.\u001b[39mbackward,\n\u001b[1;32m    515\u001b[0m         (\u001b[38;5;28mself\u001b[39m,),\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    520\u001b[0m         inputs\u001b[38;5;241m=\u001b[39minputs,\n\u001b[1;32m    521\u001b[0m     )\n\u001b[0;32m--> 522\u001b[0m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mautograd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    523\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgradient\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minputs\u001b[49m\n\u001b[1;32m    524\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/environment/miniconda3/lib/python3.11/site-packages/torch/autograd/__init__.py:266\u001b[0m, in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    261\u001b[0m     retain_graph \u001b[38;5;241m=\u001b[39m create_graph\n\u001b[1;32m    263\u001b[0m \u001b[38;5;66;03m# The reason we repeat the same comment below is that\u001b[39;00m\n\u001b[1;32m    264\u001b[0m \u001b[38;5;66;03m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[1;32m    265\u001b[0m \u001b[38;5;66;03m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[0;32m--> 266\u001b[0m \u001b[43mVariable\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_execution_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_backward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Calls into the C++ engine to run the backward pass\u001b[39;49;00m\n\u001b[1;32m    267\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtensors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    268\u001b[0m \u001b[43m    \u001b[49m\u001b[43mgrad_tensors_\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    269\u001b[0m \u001b[43m    \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    270\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    271\u001b[0m \u001b[43m    \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    272\u001b[0m \u001b[43m    \u001b[49m\u001b[43mallow_unreachable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    273\u001b[0m \u001b[43m    \u001b[49m\u001b[43maccumulate_grad\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    274\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "print(f\"\\n--- 开始为 {MODEL_CONFIG['model_name']} 进行实际训练 ---\")\n",
    "\n",
    "for epoch in range(MODEL_CONFIG['num_epochs']):\n",
    "    model.train()\n",
    "    total_train_loss = 0\n",
    "    train_bar = tqdm(train_loader, desc=f'训练轮次 {epoch+1}/{MODEL_CONFIG[\"num_epochs\"]}')\n",
    "    for inputs, labels in train_bar:\n",
    "        inputs, labels = inputs.to(device), labels.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        with torch.cuda.amp.autocast():\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "        \n",
    "        scaler.scale(loss).backward()\n",
    "        scaler.step(optimizer)\n",
    "        scaler.update()\n",
    "\n",
    "        total_train_loss += loss.item()\n",
    "        train_bar.set_postfix({'loss': f'{loss.item():.4f}', 'lr': f'{optimizer.param_groups[0][\"lr\"]:.1e}'})\n",
    "    avg_train_loss = total_train_loss / len(train_loader)\n",
    "    train_loss_history.append(avg_train_loss)\n",
    "\n",
    "    model.eval()\n",
    "    total_val_loss, total_val_correct = 0, 0\n",
    "    with torch.no_grad():\n",
    "        val_bar = tqdm(val_loader, desc=f'验证轮次 {epoch+1}/{MODEL_CONFIG[\"num_epochs\"]}')\n",
    "        for inputs, labels in val_bar:\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "            with torch.cuda.amp.autocast():\n",
    "                outputs = model(inputs)\n",
    "                loss = criterion(outputs, labels)\n",
    "            total_val_loss += loss.item()\n",
    "            _, predicted = torch.max(outputs, 1)\n",
    "            total_val_correct += (predicted == labels).sum().item()\n",
    "    \n",
    "    avg_val_loss = total_val_loss / len(val_loader)\n",
    "    val_accuracy = total_val_correct / len(val_loader.dataset)\n",
    "    val_loss_history.append(avg_val_loss)\n",
    "    val_acc_history.append(val_accuracy)\n",
    "    \n",
    "    print(f'\\n轮次 {epoch+1} | 训练损失: {avg_train_loss:.4f} | 验证损失: {avg_val_loss:.4f} | 验证准确率: {val_accuracy:.4f}')\n",
    "    scheduler.step(avg_val_loss)\n",
    "\n",
    "    if avg_val_loss < best_val_loss:\n",
    "        best_val_loss = avg_val_loss\n",
    "        torch.save(model.state_dict(), model_save_path)\n",
    "        print(f'验证损失下降。保存最佳模型到 {model_save_path}')\n",
    "        epochs_no_improve = 0\n",
    "    else:\n",
    "        epochs_no_improve += 1\n",
    "    \n",
    "    if epochs_no_improve >= early_stop_patience:\n",
    "        print(f'在 {epoch+1} 轮后触发早停机制。')\n",
    "        break\n",
    "\n",
    "print(f\"\\n--- {MODEL_CONFIG['model_name']} 训练完成！权重已保存至 {model_save_path} ---\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "447509e55acea0aa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- 开始使用 ConvNeXt-L 最佳模型进行预测 ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "使用 ConvNeXt-L 和 TTA 进行预测:  53%|█████▎    | 592/1125 [00:11<00:09, 54.51it/s]"
     ]
    }
   ],
   "source": [
    "# ===================================================================\n",
    "# Part 3: 预测与可视化\n",
    "# ===================================================================\n",
    "print(f\"\\n--- 开始使用 {MODEL_CONFIG['model_name']} 最佳模型进行预测 ---\")\n",
    "\n",
    "# --- 3.1 加载模型 ---\n",
    "# 创建一个与保存的模型结构相同的空模型\n",
    "model = models.convnext_large(weights=None) # <--- 关键修改\n",
    "num_ftrs = model.classifier[2].in_features\n",
    "model.classifier[2] = nn.Linear(num_ftrs, len(class_names))\n",
    "model.load_state_dict(torch.load(model_save_path))\n",
    "model.to(device)\n",
    "model.eval()\n",
    "\n",
    "# --- 3.2 预测 (带TTA) ---\n",
    "transform = val_test_transform # 使用标准的验证/测试变换\n",
    "test_folder = 'new data/testB'\n",
    "test_images = [img for img in os.listdir(test_folder) if img.endswith('.jpg')]\n",
    "predicts = []\n",
    "idx = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for img_name in tqdm(test_images, desc=f'使用 {MODEL_CONFIG[\"model_name\"]} 和 TTA 进行预测'):\n",
    "        img_path = os.path.join(test_folder, img_name)\n",
    "        image = Image.open(img_path).convert('RGB')\n",
    "        \n",
    "        images_tta = [\n",
    "            transform(image),\n",
    "            transform(transforms.functional.hflip(image)),\n",
    "            transform(transforms.functional.rotate(image, 15)),\n",
    "            transform(transforms.functional.rotate(image, -15))\n",
    "        ]\n",
    "        batch_tta = torch.stack(images_tta).to(device)\n",
    "        \n",
    "        with torch.cuda.amp.autocast():\n",
    "             outputs_tta = model(batch_tta)\n",
    "\n",
    "        probs_tta = torch.softmax(outputs_tta, dim=1)\n",
    "        avg_probs = torch.mean(probs_tta, dim=0)\n",
    "        _, predicted = torch.max(avg_probs, 0)\n",
    "        \n",
    "        predicts.append(predicted.item())\n",
    "        idx.append(img_name.replace('.jpg', ''))\n",
    "\n",
    "# --- 3.3 保存结果 ---\n",
    "submission = pd.DataFrame({'id': idx, 'label': predicts})\n",
    "submission['id'] = submission['id'].astype(int)\n",
    "submission = submission.sort_values(by='id')\n",
    "submission_filename = f\"{student_id}_submission_{datetime.datetime.now().strftime('%Y%m%d_%H%M%S')}.csv\"\n",
    "submission.to_csv(submission_filename, index=False)\n",
    "print(f\"预测完成，结果已保存到 {submission_filename}！\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f2ff69a-78f3-4974-ac9b-266397dfd51f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- 3.4 可视化 ---\n",
    "print(\"\\n--- 开始生成可视化图表 ---\")\n",
    "num_actual_epochs = len(train_loss_history)\n",
    "plt.style.use('seaborn-v0_8-whitegrid')\n",
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(18, 6))\n",
    "\n",
    "ax1.plot(range(1, num_actual_epochs + 1), train_loss_history, 'o-', label='训练损失 (Training Loss)')\n",
    "ax1.plot(range(1, num_actual_epochs + 1), val_loss_history, 'o-', label='验证损失 (Validation Loss)')\n",
    "ax1.set_title('训练与验证损失曲线 (ConvNeXt-Large)', fontsize=16)\n",
    "ax1.legend()\n",
    "\n",
    "ax2.plot(range(1, num_actual_epochs + 1), val_acc_history, 'o-', label='验证准确率 (Validation Accuracy)', color='g')\n",
    "ax2.set_title('验证准确率曲线 (ConvNeXt-Large)', fontsize=16)\n",
    "ax2.legend()\n",
    "\n",
    "plt.suptitle('ConvNeXt-Large 训练过程监控', fontsize=20)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "efaaea7e8ea72af4",
   "metadata": {},
   "source": [
    "---"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
