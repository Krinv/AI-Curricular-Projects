{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 学号"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "student_id = '22211360121'\n",
    "#输入学号，不输入或者输错则没有成绩\n",
    "subdir = ''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 库"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function, division\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.optim import lr_scheduler\n",
    "import numpy as np\n",
    "import torchvision\n",
    "from torchvision import datasets, models, transforms\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "import datetime\n",
    "import os\n",
    "import copy\n",
    "import glob\n",
    "import pandas as pd\n",
    "from PIL import Image\n",
    "from torch.nn import functional as F  #包含常用的函数包"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 数据处理"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_transforms = {\n",
    "    #训练集数据增强和归一化\n",
    "    'train':\n",
    "    transforms.Compose([\n",
    "        transforms.Resize(256),\n",
    "        transforms.RandomResizedCrop(224),\n",
    "        transforms.RandomVerticalFlip(p=0.3),\n",
    "        transforms.RandomAdjustSharpness(sharpness_factor=2, p=0.3),  # 随机锐化\n",
    "        transforms.RandomAutocontrast(p=0.2),                        # 自动对比度\n",
    "        transforms.RandomGrayscale(p=0.1),\n",
    "        transforms.RandomHorizontalFlip(30),\n",
    "        transforms.RandomRotation(10),\n",
    "        transforms.ColorJitter(brightness=0.2, contrast=0.2, saturation=0.2),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "        #该均值和方差是在imagenet(包含很多种类自然图像的数据集)的一个统计特征\n",
    "    ]),\n",
    "    #在验证集上仅需要归一化\n",
    "    'val':\n",
    "    transforms.Compose([\n",
    "        transforms.Resize(256),\n",
    "        transforms.CenterCrop(224),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "    ]),\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['cats', 'dogs']\n"
     ]
    }
   ],
   "source": [
    "data_dir = 'data'\n",
    "image_datasets = {\n",
    "    x: datasets.ImageFolder(os.path.join(data_dir, x), data_transforms[x])\n",
    "    for x in ['train', 'val']\n",
    "}\n",
    "dataloaders = {\n",
    "    x: torch.utils.data.DataLoader(image_datasets[x],\n",
    "                                   batch_size=16,\n",
    "                                   shuffle=True,\n",
    "                                   num_workers=4,\n",
    "                                   pin_memory=True)\n",
    "    for x in ['train', 'val']\n",
    "}\n",
    "dataset_sizes = {x: len(image_datasets[x]) for x in ['train', 'val']}\n",
    "class_names = image_datasets['train'].classes\n",
    "print(class_names)\n",
    "\n",
    "#如果有gpu使用gpu训练，没有则用cpu\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 测试数据导入"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class dataset(torch.utils.data.Dataset):\n",
    "\n",
    "    def __init__(self, file_list, transform=None):\n",
    "        self.file_list = file_list\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.file_list)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img_path = self.file_list[idx]\n",
    "        img = Image.open(img_path)\n",
    "        img_transformed = self.transform(img)\n",
    "        # 对于测试集，返回文件 ID（文件名无扩展名）而不是标签\n",
    "        fileid = os.path.basename(img_path).split('.')[0]  # 如 '1'\n",
    "        return img_transformed, fileid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "test1_dir = os.path.join('data', 'testB')\n",
    "test_list = glob.glob(os.path.join(test1_dir, '*.jpg'))\n",
    "trans = transforms.Compose([\n",
    "    transforms.Resize(256),\n",
    "    transforms.CenterCrop(224),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "])\n",
    "test_data = dataset(test_list, transform=trans)\n",
    "test_loader = torch.utils.data.DataLoader(\n",
    "    dataset=test_data,\n",
    "    batch_size=16,\n",
    "    shuffle=False,  # 预测时通常不需要打乱\n",
    "    num_workers=0   # 先设置为 0，避免多进程问题\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 可视化图像\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def imshow(inp, title=None):\n",
    "#     \"\"\"Imshow for Tensor.\"\"\"\n",
    "#     inp = inp.numpy().transpose((1, 2, 0))\n",
    "#     mean = np.array([0.485, 0.456, 0.406])\n",
    "#     std = np.array([0.229, 0.224, 0.225])\n",
    "#     inp = std * inp + mean\n",
    "#     inp = np.clip(inp, 0, 1)\n",
    "#     plt.imshow(inp)\n",
    "#     if title is not None:\n",
    "#         plt.title(title)\n",
    "#     plt.pause(0.001)  # 暂停一下，以便更新情节\n",
    "\n",
    "\n",
    "# # 获取一批训练数据\n",
    "# inputs, classes = next(iter(dataloaders['train']))\n",
    "\n",
    "# # 批量制作网格\n",
    "# out = torchvision.utils.make_grid(inputs)\n",
    "\n",
    "# imshow(out, title=[class_names[x] for x in classes])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 网络结构"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 训练模型方法"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import copy\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.cuda.amp import autocast, GradScaler\n",
    "from torch.optim import lr_scheduler\n",
    "\n",
    "# 定义训练函数\n",
    "def train_model(model, criterion, optimizer, scheduler, dataloaders, dataset_sizes, device, num_epochs=5):\n",
    "    since = time.time()\n",
    "    best_model_wts = copy.deepcopy(model.state_dict())\n",
    "    best_acc = 0.0\n",
    "    scaler = GradScaler()  # 初始化GradScaler\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        print(f'Epoch {epoch}/{num_epochs - 1}')\n",
    "        print('-' * 10)\n",
    "\n",
    "        # 每个epoch都有一个训练和验证阶段\n",
    "        for phase in ['train', 'val']:\n",
    "            running_loss = 0.0\n",
    "            running_corrects = 0\n",
    "\n",
    "            # 迭代数据\n",
    "            for inputs, labels in dataloaders[phase]:\n",
    "                inputs, labels = inputs.to(device), labels.to(device)\n",
    "\n",
    "                # 零参数梯度\n",
    "                optimizer.zero_grad()\n",
    "\n",
    "                # 前向传播\n",
    "                with autocast():  # 启用混合精度\n",
    "                    outputs = model(inputs)\n",
    "                    loss = criterion(outputs, labels)\n",
    "\n",
    "                # 反向传播 + 仅在训练阶段进行优化\n",
    "                if phase == 'train':\n",
    "                    scaler.scale(loss).backward()  # 使用Scaler进行反向传播\n",
    "                    scaler.step(optimizer)         # 更新参数\n",
    "                    scaler.update()                # 更新Scaler\n",
    "\n",
    "                running_loss += loss.item() * inputs.size(0)\n",
    "                _, preds = torch.max(outputs, 1)\n",
    "                running_corrects += torch.sum(preds == labels.data)\n",
    "\n",
    "            epoch_loss = running_loss / dataset_sizes[phase]\n",
    "            epoch_acc = running_corrects.double() / dataset_sizes[phase]\n",
    "\n",
    "            print(f'{phase} Loss: {epoch_loss:.4f} Acc: {epoch_acc:.4f}')\n",
    "\n",
    "            # 深度复制model\n",
    "            if phase == 'val' and epoch_acc > best_acc:\n",
    "                best_acc = epoch_acc\n",
    "                best_model_wts = copy.deepcopy(model.state_dict())\n",
    "\n",
    "            if phase == 'train':\n",
    "                scheduler.step()\n",
    "                model.train()  # 训练模型\n",
    "            else:\n",
    "                model.eval()   # 测试模型\n",
    "\n",
    "        print()\n",
    "\n",
    "    time_elapsed = time.time() - since\n",
    "    print(f'Training complete in {time_elapsed // 60}m {time_elapsed % 60}s')\n",
    "    print(f'Best val Acc: {best_acc:.4f}')\n",
    "\n",
    "    # 加载最佳模型权重\n",
    "    model.load_state_dict(best_model_wts)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 模型结果可视化"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize_model(model, dataloaders, class_names, num_images=6):\n",
    "    was_training = model.training\n",
    "    model.eval()\n",
    "    images_so_far = 0\n",
    "    fig = plt.figure(figsize=(10, num_images))\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for i, (inputs, labels) in enumerate(dataloaders['val']):  # ✅ 正确引用验证集 dataloader\n",
    "            inputs = inputs.to(device)\n",
    "            labels = labels.to(device)\n",
    "\n",
    "            outputs = model(inputs)\n",
    "            _, preds = torch.max(outputs, 1)\n",
    "\n",
    "            for j in range(inputs.size(0)):\n",
    "                images_so_far += 1\n",
    "                ax = plt.subplot(num_images // 2, 2, images_so_far)\n",
    "                ax.axis('off')\n",
    "                ax.set_title(f'predicted: {class_names[preds[j]]}')\n",
    "                imshow(inputs.cpu().data[j])\n",
    "\n",
    "                if images_so_far == num_images:\n",
    "                    model.train(mode=was_training)\n",
    "                    return\n",
    "\n",
    "    model.train(mode=was_training)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Softwares\\Anaconda\\envs\\Deep\\Lib\\site-packages\\torchvision\\models\\_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "c:\\Softwares\\Anaconda\\envs\\Deep\\Lib\\site-packages\\torchvision\\models\\_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet50_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet50_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision.models as models\n",
    "\n",
    "# 加载预训练的ResNet50\n",
    "resnet50 = models.resnet50(pretrained=True)\n",
    "# 修改全连接层，假设是二分类任务\n",
    "resnet50.fc = nn.Linear(resnet50.fc.in_features, 2)\n",
    "# 将模型移动到GPU（如果可用）\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "resnet50 = resnet50.to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Eff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded pretrained weights for efficientnet-b0\n"
     ]
    }
   ],
   "source": [
    "from efficientnet_pytorch import EfficientNet\n",
    "\n",
    "# 加载预训练的EfficientNet-B0（可根据需要选择B1、B2等）\n",
    "efficientnet = EfficientNet.from_pretrained('efficientnet-b0')\n",
    "# 修改全连接层，适应二分类任务\n",
    "efficientnet._fc = nn.Linear(efficientnet._fc.in_features, 2)\n",
    "# 将模型移动到GPU\n",
    "efficientnet = efficientnet.to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 分别训练"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0/39\n",
      "----------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Krinv\\AppData\\Local\\Temp\\ipykernel_20680\\919598125.py:14: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
      "  scaler = GradScaler()  # 初始化GradScaler\n",
      "C:\\Users\\Krinv\\AppData\\Local\\Temp\\ipykernel_20680\\919598125.py:33: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with autocast():  # 启用混合精度\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train Loss: 0.2317 Acc: 0.8988\n",
      "val Loss: 0.0790 Acc: 0.9725\n",
      "\n",
      "Epoch 1/39\n",
      "----------\n",
      "train Loss: 0.2560 Acc: 0.8820\n",
      "val Loss: 0.0749 Acc: 0.9677\n",
      "\n",
      "Epoch 2/39\n",
      "----------\n",
      "train Loss: 0.1015 Acc: 0.9587\n",
      "val Loss: 0.0704 Acc: 0.9718\n",
      "\n",
      "Epoch 3/39\n",
      "----------\n",
      "train Loss: 0.1034 Acc: 0.9560\n",
      "val Loss: 0.0776 Acc: 0.9710\n",
      "\n",
      "Epoch 4/39\n",
      "----------\n",
      "train Loss: 0.1178 Acc: 0.9523\n",
      "val Loss: 0.0630 Acc: 0.9748\n",
      "\n",
      "Epoch 5/39\n",
      "----------\n",
      "train Loss: 0.1141 Acc: 0.9537\n",
      "val Loss: 0.0667 Acc: 0.9745\n",
      "\n",
      "Epoch 6/39\n",
      "----------\n",
      "train Loss: 0.1203 Acc: 0.9516\n",
      "val Loss: 0.0704 Acc: 0.9723\n",
      "\n",
      "Epoch 7/39\n",
      "----------\n",
      "train Loss: 0.1313 Acc: 0.9486\n",
      "val Loss: 0.0740 Acc: 0.9708\n",
      "\n",
      "Epoch 8/39\n",
      "----------\n",
      "train Loss: 0.1363 Acc: 0.9459\n",
      "val Loss: 0.0665 Acc: 0.9753\n",
      "\n",
      "Epoch 9/39\n",
      "----------\n",
      "train Loss: 0.1347 Acc: 0.9460\n",
      "val Loss: 0.0678 Acc: 0.9718\n",
      "\n",
      "Epoch 10/39\n",
      "----------\n",
      "train Loss: 0.1322 Acc: 0.9513\n",
      "val Loss: 0.0679 Acc: 0.9733\n",
      "\n",
      "Epoch 11/39\n",
      "----------\n",
      "train Loss: 0.1263 Acc: 0.9520\n",
      "val Loss: 0.0715 Acc: 0.9713\n",
      "\n",
      "Epoch 12/39\n",
      "----------\n",
      "train Loss: 0.1415 Acc: 0.9395\n",
      "val Loss: 0.0611 Acc: 0.9770\n",
      "\n",
      "Epoch 13/39\n",
      "----------\n",
      "train Loss: 0.1410 Acc: 0.9402\n",
      "val Loss: 0.0709 Acc: 0.9713\n",
      "\n",
      "Epoch 14/39\n",
      "----------\n",
      "train Loss: 0.1295 Acc: 0.9475\n",
      "val Loss: 0.0612 Acc: 0.9783\n",
      "\n",
      "Epoch 15/39\n",
      "----------\n",
      "train Loss: 0.1329 Acc: 0.9464\n",
      "val Loss: 0.0749 Acc: 0.9705\n",
      "\n",
      "Epoch 16/39\n",
      "----------\n",
      "train Loss: 0.1218 Acc: 0.9544\n",
      "val Loss: 0.0723 Acc: 0.9733\n",
      "\n",
      "Epoch 17/39\n",
      "----------\n",
      "train Loss: 0.1255 Acc: 0.9511\n",
      "val Loss: 0.0730 Acc: 0.9720\n",
      "\n",
      "Epoch 18/39\n",
      "----------\n",
      "train Loss: 0.1255 Acc: 0.9528\n",
      "val Loss: 0.0707 Acc: 0.9735\n",
      "\n",
      "Epoch 19/39\n",
      "----------\n",
      "train Loss: 0.1292 Acc: 0.9495\n",
      "val Loss: 0.0658 Acc: 0.9730\n",
      "\n",
      "Epoch 20/39\n",
      "----------\n",
      "train Loss: 0.1323 Acc: 0.9499\n",
      "val Loss: 0.0627 Acc: 0.9760\n",
      "\n",
      "Epoch 21/39\n",
      "----------\n",
      "train Loss: 0.1252 Acc: 0.9517\n",
      "val Loss: 0.0672 Acc: 0.9728\n",
      "\n",
      "Epoch 22/39\n",
      "----------\n",
      "train Loss: 0.1296 Acc: 0.9485\n",
      "val Loss: 0.0597 Acc: 0.9765\n",
      "\n",
      "Epoch 23/39\n",
      "----------\n",
      "train Loss: 0.1302 Acc: 0.9498\n",
      "val Loss: 0.0650 Acc: 0.9738\n",
      "\n",
      "Epoch 24/39\n",
      "----------\n",
      "train Loss: 0.1341 Acc: 0.9488\n",
      "val Loss: 0.0646 Acc: 0.9738\n",
      "\n",
      "Epoch 25/39\n",
      "----------\n",
      "train Loss: 0.1329 Acc: 0.9470\n",
      "val Loss: 0.0739 Acc: 0.9733\n",
      "\n",
      "Epoch 26/39\n",
      "----------\n",
      "train Loss: 0.1216 Acc: 0.9523\n",
      "val Loss: 0.0644 Acc: 0.9753\n",
      "\n",
      "Epoch 27/39\n",
      "----------\n",
      "train Loss: 0.1300 Acc: 0.9492\n",
      "val Loss: 0.0662 Acc: 0.9733\n",
      "\n",
      "Epoch 28/39\n",
      "----------\n",
      "train Loss: 0.1306 Acc: 0.9493\n",
      "val Loss: 0.0678 Acc: 0.9728\n",
      "\n",
      "Epoch 29/39\n",
      "----------\n",
      "train Loss: 0.1281 Acc: 0.9499\n",
      "val Loss: 0.0625 Acc: 0.9753\n",
      "\n",
      "Epoch 30/39\n",
      "----------\n",
      "train Loss: 0.1365 Acc: 0.9488\n",
      "val Loss: 0.0659 Acc: 0.9728\n",
      "\n",
      "Epoch 31/39\n",
      "----------\n",
      "train Loss: 0.1261 Acc: 0.9519\n",
      "val Loss: 0.0655 Acc: 0.9760\n",
      "\n",
      "Epoch 32/39\n",
      "----------\n",
      "train Loss: 0.1384 Acc: 0.9435\n",
      "val Loss: 0.0573 Acc: 0.9788\n",
      "\n",
      "Epoch 33/39\n",
      "----------\n",
      "train Loss: 0.1317 Acc: 0.9486\n",
      "val Loss: 0.0703 Acc: 0.9725\n",
      "\n",
      "Epoch 34/39\n",
      "----------\n",
      "train Loss: 0.1394 Acc: 0.9434\n",
      "val Loss: 0.0686 Acc: 0.9738\n",
      "\n",
      "Epoch 35/39\n",
      "----------\n",
      "train Loss: 0.1328 Acc: 0.9482\n",
      "val Loss: 0.0628 Acc: 0.9755\n",
      "\n",
      "Epoch 36/39\n",
      "----------\n",
      "train Loss: 0.1297 Acc: 0.9502\n",
      "val Loss: 0.0703 Acc: 0.9735\n",
      "\n",
      "Epoch 37/39\n",
      "----------\n",
      "train Loss: 0.1319 Acc: 0.9481\n",
      "val Loss: 0.0704 Acc: 0.9718\n",
      "\n",
      "Epoch 38/39\n",
      "----------\n",
      "train Loss: 0.1290 Acc: 0.9477\n",
      "val Loss: 0.0627 Acc: 0.9755\n",
      "\n",
      "Epoch 39/39\n",
      "----------\n",
      "train Loss: 0.1287 Acc: 0.9502\n",
      "val Loss: 0.0791 Acc: 0.9683\n",
      "\n",
      "Training complete in 41.0m 50.58126974105835s\n",
      "Best val Acc: 0.9788\n"
     ]
    }
   ],
   "source": [
    "# 定义损失函数和优化器\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer_resnet = torch.optim.SGD(resnet50.parameters(), lr=0.001, momentum=0.9)\n",
    "\n",
    "# 学习率调度器\n",
    "exp_lr_scheduler = lr_scheduler.StepLR(optimizer_resnet, step_size=2, gamma=0.1)\n",
    "\n",
    "# 训练ResNet50（假设你有train_model函数）\n",
    "resnet50 = train_model(resnet50,\n",
    "    criterion,\n",
    "    optimizer_resnet,\n",
    "    exp_lr_scheduler,\n",
    "    dataloaders,\n",
    "    dataset_sizes,\n",
    "    device,\n",
    "    num_epochs=40)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0/39\n",
      "----------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Krinv\\AppData\\Local\\Temp\\ipykernel_20680\\919598125.py:14: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
      "  scaler = GradScaler()  # 初始化GradScaler\n",
      "C:\\Users\\Krinv\\AppData\\Local\\Temp\\ipykernel_20680\\919598125.py:33: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with autocast():  # 启用混合精度\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train Loss: 0.2475 Acc: 0.8913\n",
      "val Loss: 0.1038 Acc: 0.9607\n",
      "\n",
      "Epoch 1/39\n",
      "----------\n",
      "train Loss: 0.1374 Acc: 0.9412\n",
      "val Loss: 0.0966 Acc: 0.9643\n",
      "\n",
      "Epoch 2/39\n",
      "----------\n",
      "train Loss: 0.1166 Acc: 0.9498\n",
      "val Loss: 0.0978 Acc: 0.9615\n",
      "\n",
      "Epoch 3/39\n",
      "----------\n",
      "train Loss: 0.1058 Acc: 0.9575\n",
      "val Loss: 0.1014 Acc: 0.9600\n",
      "\n",
      "Epoch 4/39\n",
      "----------\n",
      "train Loss: 0.0926 Acc: 0.9606\n",
      "val Loss: 0.0976 Acc: 0.9643\n",
      "\n",
      "Epoch 5/39\n",
      "----------\n",
      "train Loss: 0.0951 Acc: 0.9595\n",
      "val Loss: 0.1050 Acc: 0.9617\n",
      "\n",
      "Epoch 6/39\n",
      "----------\n",
      "train Loss: 0.0919 Acc: 0.9604\n",
      "val Loss: 0.0926 Acc: 0.9650\n",
      "\n",
      "Epoch 7/39\n",
      "----------\n",
      "train Loss: 0.0838 Acc: 0.9641\n",
      "val Loss: 0.1011 Acc: 0.9620\n",
      "\n",
      "Epoch 8/39\n",
      "----------\n",
      "train Loss: 0.0841 Acc: 0.9647\n",
      "val Loss: 0.0959 Acc: 0.9650\n",
      "\n",
      "Epoch 9/39\n",
      "----------\n",
      "train Loss: 0.0803 Acc: 0.9669\n",
      "val Loss: 0.1136 Acc: 0.9593\n",
      "\n",
      "Epoch 10/39\n",
      "----------\n",
      "train Loss: 0.0817 Acc: 0.9667\n",
      "val Loss: 0.0987 Acc: 0.9580\n",
      "\n",
      "Epoch 11/39\n",
      "----------\n",
      "train Loss: 0.0787 Acc: 0.9661\n",
      "val Loss: 0.0982 Acc: 0.9603\n",
      "\n",
      "Epoch 12/39\n",
      "----------\n",
      "train Loss: 0.0815 Acc: 0.9646\n",
      "val Loss: 0.1030 Acc: 0.9625\n",
      "\n",
      "Epoch 13/39\n",
      "----------\n",
      "train Loss: 0.0790 Acc: 0.9661\n",
      "val Loss: 0.1069 Acc: 0.9620\n",
      "\n",
      "Epoch 14/39\n",
      "----------\n",
      "train Loss: 0.0767 Acc: 0.9689\n",
      "val Loss: 0.0954 Acc: 0.9653\n",
      "\n",
      "Epoch 15/39\n",
      "----------\n",
      "train Loss: 0.0789 Acc: 0.9678\n",
      "val Loss: 0.1031 Acc: 0.9630\n",
      "\n",
      "Epoch 16/39\n",
      "----------\n",
      "train Loss: 0.0726 Acc: 0.9707\n",
      "val Loss: 0.1123 Acc: 0.9603\n",
      "\n",
      "Epoch 17/39\n",
      "----------\n",
      "train Loss: 0.0789 Acc: 0.9682\n",
      "val Loss: 0.1225 Acc: 0.9533\n",
      "\n",
      "Epoch 18/39\n",
      "----------\n",
      "train Loss: 0.0707 Acc: 0.9703\n",
      "val Loss: 0.0933 Acc: 0.9665\n",
      "\n",
      "Epoch 19/39\n",
      "----------\n",
      "train Loss: 0.0770 Acc: 0.9657\n",
      "val Loss: 0.1096 Acc: 0.9615\n",
      "\n",
      "Epoch 20/39\n",
      "----------\n",
      "train Loss: 0.0745 Acc: 0.9685\n",
      "val Loss: 0.1156 Acc: 0.9587\n",
      "\n",
      "Epoch 21/39\n",
      "----------\n",
      "train Loss: 0.0740 Acc: 0.9692\n",
      "val Loss: 0.1019 Acc: 0.9620\n",
      "\n",
      "Epoch 22/39\n",
      "----------\n",
      "train Loss: 0.0672 Acc: 0.9732\n",
      "val Loss: 0.1032 Acc: 0.9617\n",
      "\n",
      "Epoch 23/39\n",
      "----------\n",
      "train Loss: 0.0733 Acc: 0.9697\n",
      "val Loss: 0.1213 Acc: 0.9580\n",
      "\n",
      "Epoch 24/39\n",
      "----------\n",
      "train Loss: 0.0687 Acc: 0.9728\n",
      "val Loss: 0.1111 Acc: 0.9613\n",
      "\n",
      "Epoch 25/39\n",
      "----------\n",
      "train Loss: 0.0702 Acc: 0.9718\n",
      "val Loss: 0.1086 Acc: 0.9577\n",
      "\n",
      "Epoch 26/39\n",
      "----------\n",
      "train Loss: 0.0687 Acc: 0.9722\n",
      "val Loss: 0.1132 Acc: 0.9640\n",
      "\n",
      "Epoch 27/39\n",
      "----------\n",
      "train Loss: 0.0654 Acc: 0.9741\n",
      "val Loss: 0.1071 Acc: 0.9575\n",
      "\n",
      "Epoch 28/39\n",
      "----------\n",
      "train Loss: 0.0694 Acc: 0.9707\n",
      "val Loss: 0.1484 Acc: 0.9525\n",
      "\n",
      "Epoch 29/39\n",
      "----------\n",
      "train Loss: 0.0692 Acc: 0.9701\n",
      "val Loss: 0.1337 Acc: 0.9555\n",
      "\n",
      "Epoch 30/39\n",
      "----------\n",
      "train Loss: 0.0648 Acc: 0.9732\n",
      "val Loss: 0.1234 Acc: 0.9580\n",
      "\n",
      "Epoch 31/39\n",
      "----------\n",
      "train Loss: 0.0702 Acc: 0.9699\n",
      "val Loss: 0.1443 Acc: 0.9515\n",
      "\n",
      "Epoch 32/39\n",
      "----------\n",
      "train Loss: 0.0675 Acc: 0.9732\n",
      "val Loss: 0.1534 Acc: 0.9503\n",
      "\n",
      "Epoch 33/39\n",
      "----------\n",
      "train Loss: 0.0678 Acc: 0.9698\n",
      "val Loss: 0.1382 Acc: 0.9527\n",
      "\n",
      "Epoch 34/39\n",
      "----------\n",
      "train Loss: 0.0663 Acc: 0.9728\n",
      "val Loss: 0.1347 Acc: 0.9510\n",
      "\n",
      "Epoch 35/39\n",
      "----------\n",
      "train Loss: 0.0615 Acc: 0.9737\n",
      "val Loss: 0.1321 Acc: 0.9550\n",
      "\n",
      "Epoch 36/39\n",
      "----------\n",
      "train Loss: 0.0647 Acc: 0.9719\n",
      "val Loss: 0.1093 Acc: 0.9623\n",
      "\n",
      "Epoch 37/39\n",
      "----------\n",
      "train Loss: 0.0680 Acc: 0.9718\n",
      "val Loss: 0.1342 Acc: 0.9553\n",
      "\n",
      "Epoch 38/39\n",
      "----------\n",
      "train Loss: 0.0671 Acc: 0.9708\n",
      "val Loss: 0.1244 Acc: 0.9545\n",
      "\n",
      "Epoch 39/39\n",
      "----------\n",
      "train Loss: 0.0663 Acc: 0.9723\n",
      "val Loss: 0.1097 Acc: 0.9623\n",
      "\n",
      "Training complete in 41.0m 6.702663421630859s\n",
      "Best val Acc: 0.9665\n"
     ]
    }
   ],
   "source": [
    "# 定义优化器（EfficientNet对Adam优化器效果更好）\n",
    "optimizer_efficientnet = torch.optim.Adam(efficientnet.parameters(), lr=0.0001)\n",
    "\n",
    "# 训练EfficientNet\n",
    "efficientnet = train_model(efficientnet,\n",
    "    criterion,\n",
    "    optimizer_efficientnet,  # 修正为 optimizer_efficientnet\n",
    "    exp_lr_scheduler,\n",
    "    dataloaders,\n",
    "    dataset_sizes,\n",
    "    device,\n",
    "    num_epochs=40)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(resnet50.state_dict(), \"resnet50_best.pth\")\n",
    "torch.save(efficientnet.state_dict(), \"efficientnet_best.pth\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 平均"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "# 修改ensemble_predict函数，接受模型和device参数\n",
    "def ensemble_predict(inputs, model_resnet, model_efficientnet, device):\n",
    "    model_resnet.eval()\n",
    "    model_efficientnet.eval()\n",
    "    with torch.no_grad():\n",
    "        outputs_resnet = model_resnet(inputs)\n",
    "        outputs_efficientnet = model_efficientnet(inputs)\n",
    "        probs_resnet = torch.softmax(outputs_resnet, dim=1)\n",
    "        probs_efficientnet = torch.softmax(outputs_efficientnet, dim=1)\n",
    "        avg_probs = (probs_resnet + probs_efficientnet) / 2\n",
    "        _, preds = torch.max(avg_probs, 1)\n",
    "    return preds\n",
    "\n",
    "# 定义评估集成模型的函数\n",
    "def evaluate_ensemble(model_resnet, model_efficientnet, dataloader, device):\n",
    "    model_resnet.eval()\n",
    "    model_efficientnet.eval()\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    with torch.no_grad():\n",
    "        for inputs, labels in dataloader:\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "            preds = ensemble_predict(inputs, model_resnet, model_efficientnet, device)\n",
    "            correct += (preds == labels).sum().item()\n",
    "            total += labels.size(0)\n",
    "    accuracy = correct / total\n",
    "    return accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running on: cuda:0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Softwares\\Anaconda\\envs\\Deep\\Lib\\site-packages\\torchvision\\models\\_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=None`.\n",
      "  warnings.warn(msg)\n"
     ]
    }
   ],
   "source": [
    "from torchvision import models\n",
    "from efficientnet_pytorch import EfficientNet\n",
    "\n",
    "# 定义设备\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Running on: {device}\")\n",
    "\n",
    "# 加载ResNet50\n",
    "resnet50 = models.resnet50(pretrained=False)  # 不加载预训练权重，因为我们要用你保存的权重\n",
    "resnet50.fc = nn.Linear(resnet50.fc.in_features, 2)  # 输出层改为2类\n",
    "resnet50.load_state_dict(torch.load(\"resnet50_best.pth\"))\n",
    "resnet50 = resnet50.to(device)\n",
    "\n",
    "# 加载EfficientNet-B0\n",
    "efficientnet = EfficientNet.from_name('efficientnet-b0')\n",
    "efficientnet._fc = nn.Linear(efficientnet._fc.in_features, 2)  # 输出层改为2类\n",
    "efficientnet.load_state_dict(torch.load(\"efficientnet_best.pth\"))\n",
    "efficientnet = efficientnet.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "集成模型在验证集上的准确度: 0.9880\n"
     ]
    }
   ],
   "source": [
    "# 假设你的验证集dataloader是dataloaders['val']\n",
    "val_accuracy = evaluate_ensemble(resnet50, efficientnet, dataloaders['val'], device)\n",
    "print(f'集成模型在验证集上的准确度: {val_accuracy:.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting: 100%|██████████| 274/274 [00:24<00:00, 10.96it/s]\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "# 测试\n",
    "dog_probs = []\n",
    "with torch.no_grad():\n",
    "    # 使用 tqdm 包装 test_loader 以显示进度条\n",
    "    for inputs, fileid in tqdm(test_loader, desc=\"Predicting\", total=len(test_loader)):\n",
    "        inputs = inputs.to(device)\n",
    "        # 正确调用 ensemble_predict，传递模型和设备\n",
    "        preds = ensemble_predict(inputs, resnet50, efficientnet, device)\n",
    "        dog_probs += list(zip(list(fileid), preds.cpu().numpy()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 训练"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 模型评估效果可视化"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 提交结果"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of test images: 4371\n",
      "Number of batches: 274\n"
     ]
    }
   ],
   "source": [
    "print(f\"Number of test images: {len(test_list)}\")\n",
    "print(f\"Number of batches: {len(test_loader)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "dog_probs.sort(key = lambda x : int(x[0]))\n",
    "# dog_probs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "idx = list(map(lambda x: x[0],dog_probs))\n",
    "prob = list(map(lambda x: x[1],dog_probs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "yhat = [1 if y >= 0.5 else 0 for y in prob]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4366</th>\n",
       "      <td>4366</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4367</th>\n",
       "      <td>4367</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4368</th>\n",
       "      <td>4368</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4369</th>\n",
       "      <td>4369</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4370</th>\n",
       "      <td>4370</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4371 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        id  label\n",
       "0        0      1\n",
       "1        1      1\n",
       "2        2      0\n",
       "3        3      0\n",
       "4        4      1\n",
       "...    ...    ...\n",
       "4366  4366      0\n",
       "4367  4367      0\n",
       "4368  4368      0\n",
       "4369  4369      1\n",
       "4370  4370      1\n",
       "\n",
       "[4371 rows x 2 columns]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "submission = pd.DataFrame({'id':idx,'label':yhat})\n",
    "submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission.to_csv(subdir + student_id + 'submission_{}.csv'.format(\n",
    "    datetime.datetime.now().strftime('%Y%m%d_%H%M%S')),\n",
    "                  index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Deep",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
