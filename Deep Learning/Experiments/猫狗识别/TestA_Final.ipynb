{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 学号"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "student_id = '22211360121'\n",
    "#输入学号，不输入或者输错则没有成绩\n",
    "subdir = ''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 库"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function, division\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.optim import lr_scheduler\n",
    "import numpy as np\n",
    "import torchvision\n",
    "from torchvision import datasets, models, transforms\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "import datetime\n",
    "import os\n",
    "import copy\n",
    "import glob\n",
    "import pandas as pd\n",
    "from PIL import Image\n",
    "from torch.nn import functional as F  #包含常用的函数包"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 数据处理"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_transforms = {\n",
    "    #训练集数据增强和归一化\n",
    "    'train':\n",
    "    transforms.Compose([\n",
    "        transforms.Resize(256),\n",
    "        transforms.RandomResizedCrop(224),\n",
    "        transforms.RandomHorizontalFlip(30),\n",
    "        transforms.RandomRotation(10),\n",
    "        transforms.ColorJitter(brightness=0.2, contrast=0.2, saturation=0.2),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "        #该均值和方差是在imagenet(包含很多种类自然图像的数据集)的一个统计特征\n",
    "    ]),\n",
    "    #在验证集上仅需要归一化\n",
    "    'val':\n",
    "    transforms.Compose([\n",
    "        transforms.Resize(256),\n",
    "        transforms.CenterCrop(224),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "    ]),\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['cats', 'dogs']\n"
     ]
    }
   ],
   "source": [
    "data_dir = 'data'\n",
    "image_datasets = {\n",
    "    x: datasets.ImageFolder(os.path.join(data_dir, x), data_transforms[x])\n",
    "    for x in ['train', 'val']\n",
    "}\n",
    "dataloaders = {\n",
    "    x: torch.utils.data.DataLoader(image_datasets[x],\n",
    "                                   batch_size=16,\n",
    "                                   shuffle=True,\n",
    "                                   num_workers=4,\n",
    "                                   pin_memory=True)\n",
    "    for x in ['train', 'val']\n",
    "}\n",
    "dataset_sizes = {x: len(image_datasets[x]) for x in ['train', 'val']}\n",
    "class_names = image_datasets['train'].classes\n",
    "print(class_names)\n",
    "\n",
    "#如果有gpu使用gpu训练，没有则用cpu\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 测试数据导入"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class dataset(torch.utils.data.Dataset):\n",
    "\n",
    "    def __init__(self, file_list, transform=None):\n",
    "        self.file_list = file_list\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.file_list)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img_path = self.file_list[idx]\n",
    "        img = Image.open(img_path)\n",
    "        img_transformed = self.transform(img)\n",
    "        # 对于测试集，返回文件 ID（文件名无扩展名）而不是标签\n",
    "        fileid = os.path.basename(img_path).split('.')[0]  # 如 '1'\n",
    "        return img_transformed, fileid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "test1_dir = os.path.join('data', 'test1')\n",
    "test_list = glob.glob(os.path.join(test1_dir, '*.jpg'))\n",
    "trans = transforms.Compose([\n",
    "    transforms.Resize(256),\n",
    "    transforms.CenterCrop(224),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "])\n",
    "test_data = dataset(test_list, transform=trans)\n",
    "test_loader = torch.utils.data.DataLoader(\n",
    "    dataset=test_data,\n",
    "    batch_size=16,\n",
    "    shuffle=False,  # 预测时通常不需要打乱\n",
    "    num_workers=0   # 先设置为 0，避免多进程问题\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 可视化图像\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def imshow(inp, title=None):\n",
    "#     \"\"\"Imshow for Tensor.\"\"\"\n",
    "#     inp = inp.numpy().transpose((1, 2, 0))\n",
    "#     mean = np.array([0.485, 0.456, 0.406])\n",
    "#     std = np.array([0.229, 0.224, 0.225])\n",
    "#     inp = std * inp + mean\n",
    "#     inp = np.clip(inp, 0, 1)\n",
    "#     plt.imshow(inp)\n",
    "#     if title is not None:\n",
    "#         plt.title(title)\n",
    "#     plt.pause(0.001)  # 暂停一下，以便更新情节\n",
    "\n",
    "\n",
    "# # 获取一批训练数据\n",
    "# inputs, classes = next(iter(dataloaders['train']))\n",
    "\n",
    "# # 批量制作网格\n",
    "# out = torchvision.utils.make_grid(inputs)\n",
    "\n",
    "# imshow(out, title=[class_names[x] for x in classes])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 网络结构"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 训练模型方法"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import copy\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.cuda.amp import autocast, GradScaler\n",
    "from torch.optim import lr_scheduler\n",
    "\n",
    "# 定义训练函数\n",
    "def train_model(model, criterion, optimizer, scheduler, dataloaders, dataset_sizes, device, num_epochs=5):\n",
    "    since = time.time()\n",
    "    best_model_wts = copy.deepcopy(model.state_dict())\n",
    "    best_acc = 0.0\n",
    "    scaler = GradScaler()  # 初始化GradScaler\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        print(f'Epoch {epoch}/{num_epochs - 1}')\n",
    "        print('-' * 10)\n",
    "\n",
    "        # 每个epoch都有一个训练和验证阶段\n",
    "        for phase in ['train', 'val']:\n",
    "            running_loss = 0.0\n",
    "            running_corrects = 0\n",
    "\n",
    "            # 迭代数据\n",
    "            for inputs, labels in dataloaders[phase]:\n",
    "                inputs, labels = inputs.to(device), labels.to(device)\n",
    "\n",
    "                # 零参数梯度\n",
    "                optimizer.zero_grad()\n",
    "\n",
    "                # 前向传播\n",
    "                with autocast():  # 启用混合精度\n",
    "                    outputs = model(inputs)\n",
    "                    loss = criterion(outputs, labels)\n",
    "\n",
    "                # 反向传播 + 仅在训练阶段进行优化\n",
    "                if phase == 'train':\n",
    "                    scaler.scale(loss).backward()  # 使用Scaler进行反向传播\n",
    "                    scaler.step(optimizer)         # 更新参数\n",
    "                    scaler.update()                # 更新Scaler\n",
    "\n",
    "                running_loss += loss.item() * inputs.size(0)\n",
    "                _, preds = torch.max(outputs, 1)\n",
    "                running_corrects += torch.sum(preds == labels.data)\n",
    "\n",
    "            epoch_loss = running_loss / dataset_sizes[phase]\n",
    "            epoch_acc = running_corrects.double() / dataset_sizes[phase]\n",
    "\n",
    "            print(f'{phase} Loss: {epoch_loss:.4f} Acc: {epoch_acc:.4f}')\n",
    "\n",
    "            # 深度复制model\n",
    "            if phase == 'val' and epoch_acc > best_acc:\n",
    "                best_acc = epoch_acc\n",
    "                best_model_wts = copy.deepcopy(model.state_dict())\n",
    "\n",
    "            if phase == 'train':\n",
    "                scheduler.step()\n",
    "                model.train()  # 训练模型\n",
    "            else:\n",
    "                model.eval()   # 测试模型\n",
    "\n",
    "        print()\n",
    "\n",
    "    time_elapsed = time.time() - since\n",
    "    print(f'Training complete in {time_elapsed // 60}m {time_elapsed % 60}s')\n",
    "    print(f'Best val Acc: {best_acc:.4f}')\n",
    "\n",
    "    # 加载最佳模型权重\n",
    "    model.load_state_dict(best_model_wts)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 模型结果可视化"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize_model(model, dataloaders, class_names, num_images=6):\n",
    "    was_training = model.training\n",
    "    model.eval()\n",
    "    images_so_far = 0\n",
    "    fig = plt.figure(figsize=(10, num_images))\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for i, (inputs, labels) in enumerate(dataloaders['val']):  # ✅ 正确引用验证集 dataloader\n",
    "            inputs = inputs.to(device)\n",
    "            labels = labels.to(device)\n",
    "\n",
    "            outputs = model(inputs)\n",
    "            _, preds = torch.max(outputs, 1)\n",
    "\n",
    "            for j in range(inputs.size(0)):\n",
    "                images_so_far += 1\n",
    "                ax = plt.subplot(num_images // 2, 2, images_so_far)\n",
    "                ax.axis('off')\n",
    "                ax.set_title(f'predicted: {class_names[preds[j]]}')\n",
    "                imshow(inputs.cpu().data[j])\n",
    "\n",
    "                if images_so_far == num_images:\n",
    "                    model.train(mode=was_training)\n",
    "                    return\n",
    "\n",
    "    model.train(mode=was_training)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Softwares\\Anaconda\\envs\\Deep\\Lib\\site-packages\\torchvision\\models\\_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "c:\\Softwares\\Anaconda\\envs\\Deep\\Lib\\site-packages\\torchvision\\models\\_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet50_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet50_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision.models as models\n",
    "\n",
    "# 加载预训练的ResNet50\n",
    "resnet50 = models.resnet50(pretrained=True)\n",
    "# 修改全连接层，假设是二分类任务\n",
    "resnet50.fc = nn.Linear(resnet50.fc.in_features, 2)\n",
    "# 将模型移动到GPU（如果可用）\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "resnet50 = resnet50.to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Eff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded pretrained weights for efficientnet-b0\n"
     ]
    }
   ],
   "source": [
    "from efficientnet_pytorch import EfficientNet\n",
    "\n",
    "# 加载预训练的EfficientNet-B0（可根据需要选择B1、B2等）\n",
    "efficientnet = EfficientNet.from_pretrained('efficientnet-b0')\n",
    "# 修改全连接层，适应二分类任务\n",
    "efficientnet._fc = nn.Linear(efficientnet._fc.in_features, 2)\n",
    "# 将模型移动到GPU\n",
    "efficientnet = efficientnet.to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 分别训练"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0/19\n",
      "----------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Krinv\\AppData\\Local\\Temp\\ipykernel_30600\\919598125.py:14: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
      "  scaler = GradScaler()  # 初始化GradScaler\n",
      "C:\\Users\\Krinv\\AppData\\Local\\Temp\\ipykernel_30600\\919598125.py:33: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with autocast():  # 启用混合精度\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train Loss: 0.1785 Acc: 0.9220\n",
      "val Loss: 0.0636 Acc: 0.9743\n",
      "\n",
      "Epoch 1/19\n",
      "----------\n",
      "train Loss: 0.1787 Acc: 0.9209\n",
      "val Loss: 0.0674 Acc: 0.9753\n",
      "\n",
      "Epoch 2/19\n",
      "----------\n",
      "train Loss: 0.0783 Acc: 0.9669\n",
      "val Loss: 0.0585 Acc: 0.9768\n",
      "\n",
      "Epoch 3/19\n",
      "----------\n",
      "train Loss: 0.0748 Acc: 0.9676\n",
      "val Loss: 0.0588 Acc: 0.9778\n",
      "\n",
      "Epoch 4/19\n",
      "----------\n",
      "train Loss: 0.0831 Acc: 0.9654\n",
      "val Loss: 0.0531 Acc: 0.9788\n",
      "\n",
      "Epoch 5/19\n",
      "----------\n",
      "train Loss: 0.0839 Acc: 0.9664\n",
      "val Loss: 0.0489 Acc: 0.9798\n",
      "\n",
      "Epoch 6/19\n",
      "----------\n",
      "train Loss: 0.0903 Acc: 0.9636\n",
      "val Loss: 0.0459 Acc: 0.9813\n",
      "\n",
      "Epoch 7/19\n",
      "----------\n",
      "train Loss: 0.0943 Acc: 0.9627\n",
      "val Loss: 0.0557 Acc: 0.9793\n",
      "\n",
      "Epoch 8/19\n",
      "----------\n",
      "train Loss: 0.0945 Acc: 0.9668\n",
      "val Loss: 0.0558 Acc: 0.9793\n",
      "\n",
      "Epoch 9/19\n",
      "----------\n",
      "train Loss: 0.1008 Acc: 0.9577\n",
      "val Loss: 0.0518 Acc: 0.9790\n",
      "\n",
      "Epoch 10/19\n",
      "----------\n",
      "train Loss: 0.0985 Acc: 0.9604\n",
      "val Loss: 0.0533 Acc: 0.9790\n",
      "\n",
      "Epoch 11/19\n",
      "----------\n",
      "train Loss: 0.1002 Acc: 0.9598\n",
      "val Loss: 0.0548 Acc: 0.9783\n",
      "\n",
      "Epoch 12/19\n",
      "----------\n",
      "train Loss: 0.0990 Acc: 0.9567\n",
      "val Loss: 0.0585 Acc: 0.9780\n",
      "\n",
      "Epoch 13/19\n",
      "----------\n",
      "train Loss: 0.0964 Acc: 0.9627\n",
      "val Loss: 0.0571 Acc: 0.9793\n",
      "\n",
      "Epoch 14/19\n",
      "----------\n",
      "train Loss: 0.0976 Acc: 0.9602\n",
      "val Loss: 0.0610 Acc: 0.9790\n",
      "\n",
      "Epoch 15/19\n",
      "----------\n",
      "train Loss: 0.0981 Acc: 0.9610\n",
      "val Loss: 0.0470 Acc: 0.9813\n",
      "\n",
      "Epoch 16/19\n",
      "----------\n",
      "train Loss: 0.0948 Acc: 0.9642\n",
      "val Loss: 0.0455 Acc: 0.9818\n",
      "\n",
      "Epoch 17/19\n",
      "----------\n",
      "train Loss: 0.1000 Acc: 0.9582\n",
      "val Loss: 0.0506 Acc: 0.9800\n",
      "\n",
      "Epoch 18/19\n",
      "----------\n",
      "train Loss: 0.0977 Acc: 0.9615\n",
      "val Loss: 0.0507 Acc: 0.9793\n",
      "\n",
      "Epoch 19/19\n",
      "----------\n",
      "train Loss: 0.1061 Acc: 0.9539\n",
      "val Loss: 0.0530 Acc: 0.9800\n",
      "\n",
      "Training complete in 22.0m 21.39829993247986s\n",
      "Best val Acc: 0.9818\n"
     ]
    }
   ],
   "source": [
    "# 定义损失函数和优化器\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer_resnet = torch.optim.SGD(resnet50.parameters(), lr=0.001, momentum=0.9)\n",
    "\n",
    "# 学习率调度器\n",
    "exp_lr_scheduler = lr_scheduler.StepLR(optimizer_resnet, step_size=2, gamma=0.1)\n",
    "\n",
    "# 训练ResNet50（假设你有train_model函数）\n",
    "resnet50 = train_model(resnet50,\n",
    "    criterion,\n",
    "    optimizer_resnet,\n",
    "    exp_lr_scheduler,\n",
    "    dataloaders,\n",
    "    dataset_sizes,\n",
    "    device,\n",
    "    num_epochs=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0/19\n",
      "----------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Krinv\\AppData\\Local\\Temp\\ipykernel_30600\\919598125.py:14: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
      "  scaler = GradScaler()  # 初始化GradScaler\n",
      "C:\\Users\\Krinv\\AppData\\Local\\Temp\\ipykernel_30600\\919598125.py:33: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with autocast():  # 启用混合精度\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train Loss: 0.2027 Acc: 0.9147\n",
      "val Loss: 0.0791 Acc: 0.9690\n",
      "\n",
      "Epoch 1/19\n",
      "----------\n",
      "train Loss: 0.1039 Acc: 0.9552\n",
      "val Loss: 0.0913 Acc: 0.9650\n",
      "\n",
      "Epoch 2/19\n",
      "----------\n",
      "train Loss: 0.0880 Acc: 0.9625\n",
      "val Loss: 0.0783 Acc: 0.9695\n",
      "\n",
      "Epoch 3/19\n",
      "----------\n",
      "train Loss: 0.0814 Acc: 0.9641\n",
      "val Loss: 0.0834 Acc: 0.9673\n",
      "\n",
      "Epoch 4/19\n",
      "----------\n",
      "train Loss: 0.0785 Acc: 0.9661\n",
      "val Loss: 0.0864 Acc: 0.9655\n",
      "\n",
      "Epoch 5/19\n",
      "----------\n",
      "train Loss: 0.0778 Acc: 0.9671\n",
      "val Loss: 0.0788 Acc: 0.9657\n",
      "\n",
      "Epoch 6/19\n",
      "----------\n",
      "train Loss: 0.0720 Acc: 0.9697\n",
      "val Loss: 0.0759 Acc: 0.9720\n",
      "\n",
      "Epoch 7/19\n",
      "----------\n",
      "train Loss: 0.0657 Acc: 0.9712\n",
      "val Loss: 0.0955 Acc: 0.9650\n",
      "\n",
      "Epoch 8/19\n",
      "----------\n",
      "train Loss: 0.0731 Acc: 0.9699\n",
      "val Loss: 0.0994 Acc: 0.9643\n",
      "\n",
      "Epoch 9/19\n",
      "----------\n",
      "train Loss: 0.0634 Acc: 0.9736\n",
      "val Loss: 0.0850 Acc: 0.9667\n",
      "\n",
      "Epoch 10/19\n",
      "----------\n",
      "train Loss: 0.0697 Acc: 0.9699\n",
      "val Loss: 0.0876 Acc: 0.9698\n",
      "\n",
      "Epoch 11/19\n",
      "----------\n",
      "train Loss: 0.0609 Acc: 0.9728\n",
      "val Loss: 0.0931 Acc: 0.9703\n",
      "\n",
      "Epoch 12/19\n",
      "----------\n",
      "train Loss: 0.0637 Acc: 0.9729\n",
      "val Loss: 0.0884 Acc: 0.9645\n",
      "\n",
      "Epoch 13/19\n",
      "----------\n",
      "train Loss: 0.0673 Acc: 0.9707\n",
      "val Loss: 0.0857 Acc: 0.9695\n",
      "\n",
      "Epoch 14/19\n",
      "----------\n",
      "train Loss: 0.0610 Acc: 0.9757\n",
      "val Loss: 0.0938 Acc: 0.9673\n",
      "\n",
      "Epoch 15/19\n",
      "----------\n",
      "train Loss: 0.0600 Acc: 0.9752\n",
      "val Loss: 0.0970 Acc: 0.9637\n",
      "\n",
      "Epoch 16/19\n",
      "----------\n",
      "train Loss: 0.0597 Acc: 0.9754\n",
      "val Loss: 0.0928 Acc: 0.9700\n",
      "\n",
      "Epoch 17/19\n",
      "----------\n",
      "train Loss: 0.0544 Acc: 0.9777\n",
      "val Loss: 0.1037 Acc: 0.9577\n",
      "\n",
      "Epoch 18/19\n",
      "----------\n",
      "train Loss: 0.0586 Acc: 0.9755\n",
      "val Loss: 0.0930 Acc: 0.9647\n",
      "\n",
      "Epoch 19/19\n",
      "----------\n",
      "train Loss: 0.0562 Acc: 0.9762\n",
      "val Loss: 0.0880 Acc: 0.9708\n",
      "\n",
      "Training complete in 27.0m 4.441390514373779s\n",
      "Best val Acc: 0.9720\n"
     ]
    }
   ],
   "source": [
    "# 定义优化器（EfficientNet对Adam优化器效果更好）\n",
    "optimizer_efficientnet = torch.optim.Adam(efficientnet.parameters(), lr=0.0001)\n",
    "\n",
    "# 训练EfficientNet\n",
    "efficientnet = train_model(efficientnet,\n",
    "    criterion,\n",
    "    optimizer_efficientnet,  # 修正为 optimizer_efficientnet\n",
    "    exp_lr_scheduler,\n",
    "    dataloaders,\n",
    "    dataset_sizes,\n",
    "    device,\n",
    "    num_epochs=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(resnet50.state_dict(), \"resnet50_best.pth\")\n",
    "torch.save(efficientnet.state_dict(), \"efficientnet_best.pth\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 平均"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "# 修改ensemble_predict函数，接受模型和device参数\n",
    "def ensemble_predict(inputs, model_resnet, model_efficientnet, device):\n",
    "    model_resnet.eval()\n",
    "    model_efficientnet.eval()\n",
    "    with torch.no_grad():\n",
    "        outputs_resnet = model_resnet(inputs)\n",
    "        outputs_efficientnet = model_efficientnet(inputs)\n",
    "        probs_resnet = torch.softmax(outputs_resnet, dim=1)\n",
    "        probs_efficientnet = torch.softmax(outputs_efficientnet, dim=1)\n",
    "        avg_probs = (probs_resnet + probs_efficientnet) / 2\n",
    "        _, preds = torch.max(avg_probs, 1)\n",
    "    return preds\n",
    "\n",
    "# 定义评估集成模型的函数\n",
    "def evaluate_ensemble(model_resnet, model_efficientnet, dataloader, device):\n",
    "    model_resnet.eval()\n",
    "    model_efficientnet.eval()\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    with torch.no_grad():\n",
    "        for inputs, labels in dataloader:\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "            preds = ensemble_predict(inputs, model_resnet, model_efficientnet, device)\n",
    "            correct += (preds == labels).sum().item()\n",
    "            total += labels.size(0)\n",
    "    accuracy = correct / total\n",
    "    return accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running on: cuda:0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Softwares\\Anaconda\\envs\\Deep\\Lib\\site-packages\\torchvision\\models\\_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=None`.\n",
      "  warnings.warn(msg)\n"
     ]
    }
   ],
   "source": [
    "from torchvision import models\n",
    "from efficientnet_pytorch import EfficientNet\n",
    "\n",
    "# 定义设备\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Running on: {device}\")\n",
    "\n",
    "# 加载ResNet50\n",
    "resnet50 = models.resnet50(pretrained=False)  # 不加载预训练权重，因为我们要用你保存的权重\n",
    "resnet50.fc = nn.Linear(resnet50.fc.in_features, 2)  # 输出层改为2类\n",
    "resnet50.load_state_dict(torch.load(\"resnet50_best.pth\"))\n",
    "resnet50 = resnet50.to(device)\n",
    "\n",
    "# 加载EfficientNet-B0\n",
    "efficientnet = EfficientNet.from_name('efficientnet-b0')\n",
    "efficientnet._fc = nn.Linear(efficientnet._fc.in_features, 2)  # 输出层改为2类\n",
    "efficientnet.load_state_dict(torch.load(\"efficientnet_best.pth\"))\n",
    "efficientnet = efficientnet.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "集成模型在验证集上的准确度: 0.9898\n"
     ]
    }
   ],
   "source": [
    "# 假设你的验证集dataloader是dataloaders['val']\n",
    "val_accuracy = evaluate_ensemble(resnet50, efficientnet, dataloaders['val'], device)\n",
    "print(f'集成模型在验证集上的准确度: {val_accuracy:.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting:   0%|          | 0/313 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting: 100%|██████████| 313/313 [00:45<00:00,  6.95it/s]\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "# 测试\n",
    "dog_probs = []\n",
    "with torch.no_grad():\n",
    "    # 使用 tqdm 包装 test_loader 以显示进度条\n",
    "    for inputs, fileid in tqdm(test_loader, desc=\"Predicting\", total=len(test_loader)):\n",
    "        inputs = inputs.to(device)\n",
    "        # 正确调用 ensemble_predict，传递模型和设备\n",
    "        preds = ensemble_predict(inputs, resnet50, efficientnet, device)\n",
    "        dog_probs += list(zip(list(fileid), preds.cpu().numpy()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 训练"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 模型评估效果可视化"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 提交结果"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of test images: 5000\n",
      "Number of batches: 313\n"
     ]
    }
   ],
   "source": [
    "print(f\"Number of test images: {len(test_list)}\")\n",
    "print(f\"Number of batches: {len(test_loader)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "dog_probs.sort(key = lambda x : int(x[0]))\n",
    "# dog_probs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "idx = list(map(lambda x: x[0],dog_probs))\n",
    "prob = list(map(lambda x: x[1],dog_probs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "yhat = [1 if y >= 0.5 else 0 for y in prob]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4995</th>\n",
       "      <td>4995</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4996</th>\n",
       "      <td>4996</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4997</th>\n",
       "      <td>4997</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4998</th>\n",
       "      <td>4998</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4999</th>\n",
       "      <td>4999</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5000 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        id  label\n",
       "0        0      1\n",
       "1        1      0\n",
       "2        2      0\n",
       "3        3      1\n",
       "4        4      0\n",
       "...    ...    ...\n",
       "4995  4995      0\n",
       "4996  4996      1\n",
       "4997  4997      0\n",
       "4998  4998      0\n",
       "4999  4999      1\n",
       "\n",
       "[5000 rows x 2 columns]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "submission = pd.DataFrame({'id':idx,'label':yhat})\n",
    "submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission.to_csv(subdir + student_id + 'submission_{}.csv'.format(\n",
    "    datetime.datetime.now().strftime('%Y%m%d_%H%M%S')),\n",
    "                  index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Deep",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
