{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dca2f258",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [0], train_loss: 3.0091, val_loss: 2.9705, val_acc: 0.3097\n",
      "Epoch [1], train_loss: 1.6237, val_loss: 2.6915, val_acc: 0.3540\n",
      "Epoch [2], train_loss: 1.1929, val_loss: 1.5127, val_acc: 0.6250\n",
      "Epoch [3], train_loss: 0.9904, val_loss: 1.4449, val_acc: 0.6437\n",
      "Epoch [4], train_loss: 0.8950, val_loss: 0.9802, val_acc: 0.7435\n",
      "Epoch [5], train_loss: 0.8320, val_loss: 1.0078, val_acc: 0.7351\n",
      "Epoch [6], train_loss: 0.7413, val_loss: 0.7835, val_acc: 0.7915\n",
      "Epoch [7], train_loss: 0.7108, val_loss: 0.9123, val_acc: 0.7551\n",
      "Epoch [8], train_loss: 0.6700, val_loss: 0.9814, val_acc: 0.7528\n",
      "Epoch [9], train_loss: 0.6008, val_loss: 0.7232, val_acc: 0.8083\n",
      "Epoch [10], train_loss: 0.6036, val_loss: 0.8955, val_acc: 0.7537\n",
      "Epoch [11], train_loss: 0.5447, val_loss: 0.7276, val_acc: 0.8102\n",
      "Epoch [12], train_loss: 0.5216, val_loss: 0.6415, val_acc: 0.8214\n",
      "Epoch [13], train_loss: 0.5336, val_loss: 0.5883, val_acc: 0.8354\n",
      "Epoch [14], train_loss: 0.5103, val_loss: 0.7287, val_acc: 0.7985\n",
      "Epoch [15], train_loss: 0.4905, val_loss: 0.6452, val_acc: 0.8358\n",
      "Epoch [16], train_loss: 0.4804, val_loss: 0.5756, val_acc: 0.8498\n",
      "Epoch [17], train_loss: 0.4366, val_loss: 0.6307, val_acc: 0.8372\n",
      "Epoch [18], train_loss: 0.4725, val_loss: 0.7742, val_acc: 0.7938\n",
      "Epoch [19], train_loss: 0.4519, val_loss: 0.6561, val_acc: 0.8288\n",
      "Epoch [20], train_loss: 0.4247, val_loss: 0.5339, val_acc: 0.8503\n",
      "Epoch [21], train_loss: 0.3835, val_loss: 0.9599, val_acc: 0.7523\n",
      "Epoch [22], train_loss: 0.3885, val_loss: 0.6774, val_acc: 0.8354\n",
      "Epoch [23], train_loss: 0.3885, val_loss: 0.6025, val_acc: 0.8349\n",
      "Epoch [24], train_loss: 0.3751, val_loss: 0.6227, val_acc: 0.8372\n",
      "Epoch [25], train_loss: 0.3653, val_loss: 1.9733, val_acc: 0.4902\n",
      "Epoch [26], train_loss: 0.3622, val_loss: 0.7909, val_acc: 0.7966\n",
      "Epoch [27], train_loss: 0.3517, val_loss: 0.5961, val_acc: 0.8489\n",
      "Epoch [28], train_loss: 0.3560, val_loss: 0.5912, val_acc: 0.8498\n",
      "Epoch [29], train_loss: 0.3599, val_loss: 0.8344, val_acc: 0.7840\n"
     ]
    }
   ],
   "source": [
    "# 导入必要的库\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import datasets, transforms\n",
    "from facenet_pytorch import InceptionResnetV1  # 使用facenet-pytorch库中的预训练模型\n",
    "import pandas as pd\n",
    "import os\n",
    "import glob\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "import datetime\n",
    "\n",
    "# 设置计算设备（优先使用GPU）\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "# 加载预训练模型\n",
    "facenet_model = InceptionResnetV1(pretrained=None).eval()\n",
    "\n",
    "# 加载本地权重\n",
    "state_dict = torch.load('vggface2.pth')\n",
    "\n",
    "# 应用权重\n",
    "facenet_model.load_state_dict(state_dict)\n",
    "facenet_model.eval()\n",
    "\n",
    "# -------------------- 1. 数据预处理 --------------------\n",
    "# 定义训练数据增强和预处理流程\n",
    "train_transform = transforms.Compose([\n",
    "    transforms.RandomRotation(degrees=(0, 20)),\n",
    "    transforms.RandomGrayscale(0.1),\n",
    "    transforms.Resize((160, 160)),  # FaceNet标准输入尺寸为160x160\n",
    "    transforms.RandomHorizontalFlip(),  # 随机水平翻转（数据增强）\n",
    "    transforms.ColorJitter(brightness=.5, hue=.3),\n",
    "    transforms.ToTensor(),  # 转换为Tensor格式（范围[0,1]）\n",
    "    transforms.Normalize(mean=[0.5, 0.5, 0.5], std=[0.5, 0.5, 0.5])  # 标准化到[-1, 1]\n",
    "])\n",
    "\n",
    "# 加载训练数据集（需要调整数据集路径）\n",
    "data_dir = './data/105_classes_pins_dataset'\n",
    "dataset = datasets.ImageFolder(data_dir, transform=train_transform)\n",
    "\n",
    "# 数据集划分（80%训练，20%验证）\n",
    "train_size = int(0.8 * len(dataset))\n",
    "val_size = len(dataset) - train_size\n",
    "train_dataset, val_dataset = torch.utils.data.random_split(dataset, [train_size, val_size])\n",
    "\n",
    "# 创建数据加载器\n",
    "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True, num_workers=4)\n",
    "val_loader = DataLoader(val_dataset, batch_size=32, shuffle=False, num_workers=4)\n",
    "\n",
    "# -------------------- 2. 加载预训练模型 --------------------\n",
    "model = facenet_model\n",
    "\n",
    "# -------------------- 3. 定义基础训练类 --------------------\n",
    "class ImageClassificationBase(nn.Module):\n",
    "    def training_step(self, batch):\n",
    "        \"\"\"训练步骤\"\"\"\n",
    "        images, labels = batch\n",
    "        out = self(images)  # 前向传播\n",
    "        loss = F.cross_entropy(out, labels)  # 计算交叉熵损失\n",
    "        return loss\n",
    "\n",
    "    def validation_step(self, batch):\n",
    "        \"\"\"验证步骤\"\"\"\n",
    "        images, labels = batch\n",
    "        out = self(images)\n",
    "        loss = F.cross_entropy(out, labels)\n",
    "        acc = accuracy(out, labels)  # 计算准确率\n",
    "        return {'val_loss': loss.detach(), 'val_acc': acc}\n",
    "\n",
    "    def validation_epoch_end(self, outputs):\n",
    "        \"\"\"验证周期结束聚合结果\"\"\"\n",
    "        batch_losses = [x['val_loss'] for x in outputs]\n",
    "        epoch_loss = torch.stack(batch_losses).mean()  # 平均损失\n",
    "        batch_accs = [x['val_acc'] for x in outputs]\n",
    "        epoch_acc = torch.stack(batch_accs).mean()     # 平均准确率\n",
    "        return {'val_loss': epoch_loss.item(), 'val_acc': epoch_acc.item()}\n",
    "\n",
    "    def epoch_end(self, epoch, result):\n",
    "        \"\"\"周期结束日志打印\"\"\"\n",
    "        print(\"Epoch [{}], train_loss: {:.4f}, val_loss: {:.4f}, val_acc: {:.4f}\".format(\n",
    "            epoch, result['train_loss'], result['val_loss'], result['val_acc']))\n",
    "\n",
    "# -------------------- 4. 定义分类模型 --------------------\n",
    "num_classes = 105  # 根据实际类别数修改\n",
    "\n",
    "class FaceNetClassifier(ImageClassificationBase):\n",
    "    \"\"\"FaceNet分类器（在预训练模型基础上添加全连接层）\"\"\"\n",
    "    def __init__(self, backbone):\n",
    "        super().__init__()\n",
    "        self.backbone = backbone\n",
    "        \n",
    "        # 冻结预训练层（可选）\n",
    "        for name, param in self.backbone.named_parameters():\n",
    "            if 'block8' in name or 'block7' in name:  # 解冻后两层\n",
    "                param.requires_grad = True\n",
    "            else:\n",
    "                param.requires_grad = False\n",
    "        \n",
    "        # 添加分类层（FaceNet输出维度512）\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Linear(512, 256),\n",
    "            nn.BatchNorm1d(256),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.5),\n",
    "            nn.Linear(256, num_classes)\n",
    "        )  \n",
    "\n",
    "    def forward(self, x):\n",
    "        \"\"\"前向传播\"\"\"\n",
    "        embeddings = self.backbone(x)  # 提取特征嵌入\n",
    "        return self.classifier(embeddings)  # 分类预测\n",
    "\n",
    "# 实例化模型并移至设备\n",
    "facenet_model = FaceNetClassifier(model).to(device)\n",
    "\n",
    "# -------------------- 5. 训练配置 --------------------\n",
    "from torch.optim import Adam\n",
    "optimizer = Adam(facenet_model.parameters(), lr=0.001)  # 只优化分类器参数\n",
    "\n",
    "def accuracy(outputs, labels):\n",
    "    \"\"\"计算准确率\"\"\"\n",
    "    _, preds = torch.max(outputs, dim=1)\n",
    "    return torch.tensor(torch.sum(preds == labels).item() / len(preds))\n",
    "\n",
    "# 训练函数\n",
    "def fit(epochs, model, train_loader, val_loader, optimizer):\n",
    "    history = []\n",
    "    for epoch in range(epochs):\n",
    "        # 训练阶段\n",
    "        model.train()\n",
    "        train_losses = []\n",
    "        for batch in train_loader:\n",
    "            images, labels = batch[0].to(device), batch[1].to(device)\n",
    "            loss = model.training_step((images, labels))\n",
    "            train_losses.append(loss)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "        # 验证阶段\n",
    "        result = evaluate(model, val_loader)\n",
    "        result['train_loss'] = torch.stack(train_losses).mean().item()\n",
    "        model.epoch_end(epoch, result)\n",
    "        history.append(result)\n",
    "    return history\n",
    "\n",
    "# 验证函数\n",
    "def evaluate(model, val_loader):\n",
    "    model.eval()\n",
    "    outputs = []\n",
    "    for batch in val_loader:\n",
    "        images, labels = batch[0].to(device), batch[1].to(device)\n",
    "        outputs.append(model.validation_step((images, labels)))\n",
    "    return model.validation_epoch_end(outputs)\n",
    "\n",
    "# 开始训练\n",
    "history = fit(30, facenet_model, train_loader, val_loader, optimizer)\n",
    "\n",
    "# -------------------- 6. 测试与提交 --------------------\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "99474488",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TestDataset(torch.utils.data.Dataset):\n",
    "    \"\"\"测试数据集类\"\"\"\n",
    "    def __init__(self, file_list, transform=None):\n",
    "        self.file_list = file_list  # 测试文件路径列表\n",
    "        self.transform = transform  # 预处理流程\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.file_list)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img_path = self.file_list[idx]\n",
    "        img = Image.open(img_path).convert('RGB')  # 强制转换为RGB格式\n",
    "        if self.transform:\n",
    "            img = self.transform(img)\n",
    "        file_id = os.path.basename(img_path).split('.')[0]  # 从文件名提取ID\n",
    "        return img, file_id\n",
    "\n",
    "# 测试数据预处理（与训练一致，去掉数据增强）\n",
    "test_transform = transforms.Compose([\n",
    "    transforms.Resize((160, 160)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.5, 0.5, 0.5], std=[0.5, 0.5, 0.5])\n",
    "])\n",
    "\n",
    "# 加载测试数据\n",
    "test_dir = './data/test2'\n",
    "test_list = glob.glob(os.path.join(test_dir, '*.jpg'))\n",
    "test_dataset = TestDataset(test_list, transform=test_transform)\n",
    "test_loader = DataLoader(test_dataset, batch_size=32, shuffle=False)  # 保持顺序\n",
    "\n",
    "def predict(model, test_loader, device):\n",
    "    \"\"\"预测函数\"\"\"\n",
    "    model.eval()\n",
    "    predictions = []\n",
    "    file_ids = []\n",
    "    with torch.no_grad():\n",
    "        for data, fileid in test_loader:\n",
    "            data = data.to(device)\n",
    "            outputs = model(data)\n",
    "            _, preds = torch.max(outputs, dim=1)\n",
    "            predictions.extend(preds.cpu().numpy())  # 转回CPU处理\n",
    "            file_ids.extend(fileid)\n",
    "    return file_ids, predictions\n",
    "\n",
    "# 生成预测结果\n",
    "file_ids, predictions = predict(facenet_model, test_loader, device)\n",
    "\n",
    "# 获取类别名称\n",
    "class_names = dataset.classes\n",
    "\n",
    "# 将预测索引转换为类别名称\n",
    "predicted_labels = [class_names[pred] for pred in predictions]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "6d7cffa6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 创建DataFrame\n",
    "submission_df = pd.DataFrame({'id': file_ids, 'label': predicted_labels})\n",
    "\n",
    "# 保存为CSV文件\n",
    "submission_df.to_csv('submission.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "3c60712f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "name_to_submission_label_map = {\n",
    "  \"pins_Adriana Lima\": 0,\n",
    "  \"pins_Alex Lawther\": 1,\n",
    "  \"pins_Alexandra Daddario\": 2,\n",
    "  \"pins_Alvaro Morte\": 3,\n",
    "  \"pins_alycia dabnem carey\": 4,\n",
    "  \"pins_Amanda Crew\": 5,\n",
    "  \"pins_amber heard\": 6,\n",
    "  \"pins_Andy Samberg\": 7,\n",
    "  \"pins_Anne Hathaway\": 8,\n",
    "  \"pins_Anthony Mackie\": 9,\n",
    "  \"pins_Avril Lavigne\": 10,\n",
    "  \"pins_barack obama\": 11,\n",
    "  \"pins_barbara palvin\": 12,\n",
    "  \"pins_Ben Affleck\": 13,\n",
    "  \"pins_Bill Gates\": 14,\n",
    "  \"pins_Bobby Morley\": 15,\n",
    "  \"pins_Brenton Thwaites\": 16,\n",
    "  \"pins_Brian J. Smith\": 17,\n",
    "  \"pins_Brie Larson\": 18,\n",
    "  \"pins_camila mendes\": 19,\n",
    "  \"pins_Chris Evans\": 20,\n",
    "  \"pins_Chris Hemsworth\": 21,\n",
    "  \"pins_Chris Pratt\": 22,\n",
    "  \"pins_Christian Bale\": 23,\n",
    "  \"pins_Cristiano Ronaldo\": 24,\n",
    "  \"pins_Danielle Panabaker\": 25,\n",
    "  \"pins_Dominic Purcell\": 26,\n",
    "  \"pins_Dwayne Johnson\": 27,\n",
    "  \"pins_Eliza Taylor\": 28,\n",
    "  \"pins_Elizabeth Lail\": 29,\n",
    "  \"pins_elizabeth olsen\": 30,\n",
    "  \"pins_ellen page\": 31,\n",
    "  \"pins_elon musk\": 32,\n",
    "  \"pins_Emilia Clarke\": 33,\n",
    "  \"pins_Emma Stone\": 34,\n",
    "  \"pins_Emma Watson\": 35,\n",
    "  \"pins_gal gadot\": 36,\n",
    "  \"pins_grant gustin\": 37,\n",
    "  \"pins_Gwyneth Paltrow\": 38,\n",
    "  \"pins_Henry Cavil\": 39,\n",
    "  \"pins_Hugh Jackman\": 40,\n",
    "  \"pins_Inbar Lavi\": 41,\n",
    "  \"pins_Irina Shayk\": 42,\n",
    "  \"pins_Jake Mcdorman\": 43,\n",
    "  \"pins_Jason Momoa\": 44,\n",
    "  \"pins_jeff bezos\": 45,\n",
    "  \"pins_Jennifer Lawrence\": 46,\n",
    "  \"pins_Jeremy Renner\": 47,\n",
    "  \"pins_Jessica Barden\": 48,\n",
    "  \"pins_Jimmy Fallon\": 49,\n",
    "  \"pins_Johnny Depp\": 50,\n",
    "  \"pins_Josh Radnor\": 51,\n",
    "  \"pins_Katharine Mcphee\": 52,\n",
    "  \"pins_Katherine Langford\": 53,\n",
    "  \"pins_Keanu Reeves\": 54,\n",
    "  \"pins_kiernen shipka\": 55,\n",
    "  \"pins_Krysten Ritter\": 56,\n",
    "  \"pins_Leonardo DiCaprio\": 57,\n",
    "  \"pins_Lili Reinhart\": 58,\n",
    "  \"pins_Lindsey Morgan\": 59,\n",
    "  \"pins_Lionel Messi\": 60,\n",
    "  \"pins_Logan Lerman\": 61,\n",
    "  \"pins_Madelaine Petsch\": 62,\n",
    "  \"pins_Maisie Williams\": 63,\n",
    "  \"pins_margot robbie\": 64,\n",
    "  \"pins_Maria Pedraza\": 65,\n",
    "  \"pins_Marie Avgeropoulos\": 66,\n",
    "  \"pins_Mark Ruffalo\": 67,\n",
    "  \"pins_Mark Zuckerberg\": 68,\n",
    "  \"pins_Megan Fox\": 69,\n",
    "  \"pins_melissa fumero\": 70,\n",
    "  \"pins_Miley Cyrus\": 71,\n",
    "  \"pins_Millie Bobby Brown\": 72,\n",
    "  \"pins_Morena Baccarin\": 73,\n",
    "  \"pins_Morgan Freeman\": 74,\n",
    "  \"pins_Nadia Hilker\": 75,\n",
    "  \"pins_Natalie Dormer\": 76,\n",
    "  \"pins_Natalie Portman\": 77,\n",
    "  \"pins_Neil Patrick Harris\": 78,\n",
    "  \"pins_Pedro Alonso\": 79,\n",
    "  \"pins_Penn Badgley\": 80,\n",
    "  \"pins_Rami Malek\": 81,\n",
    "  \"pins_Rebecca Ferguson\": 82,\n",
    "  \"pins_Richard Harmon\": 83,\n",
    "  \"pins_Rihanna\": 84,\n",
    "  \"pins_Robert De Niro\": 85,\n",
    "  \"pins_Robert Downey Jr\": 86,\n",
    "  \"pins_Sarah Wayne Callies\": 87,\n",
    "  \"pins_scarlett johansson\": 88,\n",
    "  \"pins_Selena Gomez\": 89,\n",
    "  \"pins_Shakira Isabel Mebarak\": 90,\n",
    "  \"pins_Sophie Turner\": 91,\n",
    "  \"pins_Stephen Amell\": 92,\n",
    "  \"pins_Taylor Swift\": 93,\n",
    "  \"pins_Tom Cruise\": 94,\n",
    "  \"pins_tom ellis\": 95,\n",
    "  \"pins_Tom Hardy\": 96,\n",
    "  \"pins_Tom Hiddleston\": 97,\n",
    "  \"pins_Tom Holland\": 98,\n",
    "  \"pins_Tuppence Middleton\": 99,\n",
    "  \"pins_Ursula Corbero\": 100,\n",
    "  \"pins_Wentworth Miller\": 101,\n",
    "  \"pins_Zac Efron\": 102,\n",
    "  \"pins_Zendaya\": 103,\n",
    "  \"pins_Zoe Saldana\": 104\n",
    "}\n",
    "\n",
    "def get_submission_label(class_name):\n",
    "    # 直接使用 class_name 在映射中查找提交标签\n",
    "    return name_to_submission_label_map.get(class_name, class_name)\n",
    "\n",
    "# 读取 CSV 文件\n",
    "df = pd.read_csv('submission.csv')\n",
    "\n",
    "# 应用标签映射\n",
    "df['label'] = df['label'].apply(get_submission_label)\n",
    "\n",
    "# 按 'id' 列排序\n",
    "try:\n",
    "    df['id'] = df['id'].astype(int)  # 尝试将 'id' 转换为整数\n",
    "    df = df.sort_values(by='id')     # 按数值排序\n",
    "except ValueError:\n",
    "    df = df.sort_values(by='id')     # 如果转换失败，按字符串排序\n",
    "\n",
    "# 保存处理后的数据到新的 CSV 文件\n",
    "df.to_csv('22211360121' + 'submission_{}.csv'.format(datetime.datetime.now().strftime('%Y%m%d_%H%M%S')), index=False)\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
