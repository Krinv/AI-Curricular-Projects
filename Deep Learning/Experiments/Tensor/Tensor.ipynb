{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 张量练习部分"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.6.0+cu126\n"
     ]
    }
   ],
   "source": [
    "#其他\n",
    "import matplotlib\n",
    "import numpy as np\n",
    "\n",
    "#torch库\n",
    "import torch\n",
    "print(torch.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1., 2.],\n",
       "        [3., 4.]])"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#直接数据创建Tensor\n",
    "data=[[1,2],[3,4]]\n",
    "x_data=torch.Tensor(data)\n",
    "x_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "#numpy创建Tensor\n",
    "np_array = np.array(data)\n",
    "x_np = torch.from_numpy(np_array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ones Tensor: \n",
      " tensor([[1., 1.],\n",
      "        [1., 1.]]) \n",
      "\n",
      "Random Tensor: \n",
      " tensor([[0.2053, 0.5238],\n",
      "        [0.1570, 0.5318]]) \n",
      "\n"
     ]
    }
   ],
   "source": [
    "#其他Tensor创建\n",
    "#保留x数据的属性\n",
    "x_ones=torch.ones_like(x_data) \n",
    "print(f\"Ones Tensor: \\n {x_ones} \\n\")\n",
    "#覆盖x_data的属性\n",
    "x_rand = torch.rand_like(x_data, dtype=torch.float) \n",
    "print(f\"Random Tensor: \\n {x_rand} \\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Tensor: \n",
      " tensor([[0.3533, 0.6410, 0.7110],\n",
      "        [0.0739, 0.5507, 0.5211]]) \n",
      "\n",
      "Ones Tensor: \n",
      " tensor([[1., 1., 1.],\n",
      "        [1., 1., 1.]]) \n",
      "\n",
      "Zeros Tensor: \n",
      " tensor([[0., 0., 0.],\n",
      "        [0., 0., 0.]])\n"
     ]
    }
   ],
   "source": [
    "#从常数、随机数创建\n",
    "shape=(2,3,)\n",
    "\n",
    "rand_tensor=torch.rand(shape)\n",
    "ones_tensor=torch.ones(shape)\n",
    "zeros_tensor=torch.zeros(shape)\n",
    "\n",
    "print(f\"Random Tensor: \\n {rand_tensor} \\n\")\n",
    "print(f\"Ones Tensor: \\n {ones_tensor} \\n\")\n",
    "print(f\"Zeros Tensor: \\n {zeros_tensor}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "形状: torch.Size([3, 4])\n",
      "数据类型: torch.float32\n",
      "存储设备: cpu\n"
     ]
    }
   ],
   "source": [
    "#Tensor属性\n",
    "tensor=torch.rand(3,4)\n",
    "\n",
    "print(f\"形状: {tensor.shape}\")\n",
    "print(f\"数据类型: {tensor.dtype}\")\n",
    "print(f\"存储设备: {tensor.device}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "存储位置：cuda:0\n"
     ]
    }
   ],
   "source": [
    "#将Tensor移动到GPU\n",
    "if torch.cuda.is_available():\n",
    "    tensor=tensor.to('cuda')\n",
    "\n",
    "print(f\"存储位置：{tensor.device}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1., 0., 1., 1.],\n",
       "        [1., 0., 1., 1.],\n",
       "        [1., 0., 1., 1.],\n",
       "        [1., 0., 1., 1.]])"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Tensor索引与切片\n",
    "tensor=torch.ones(4,4)\n",
    "tensor[:,1]=0 #第2列为0\n",
    "tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1., 0., 1., 1., 1., 0., 1., 1., 1., 0., 1., 1.],\n",
      "        [1., 0., 1., 1., 1., 0., 1., 1., 1., 0., 1., 1.],\n",
      "        [1., 0., 1., 1., 1., 0., 1., 1., 1., 0., 1., 1.],\n",
      "        [1., 0., 1., 1., 1., 0., 1., 1., 1., 0., 1., 1.]])\n"
     ]
    }
   ],
   "source": [
    "#合并Tensors\n",
    "t1=torch.cat([tensor,tensor,tensor],dim=1) #输入张量，沿着第二个维度（列）将多个张量拼接\n",
    "print(t1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor.mul(tensor) \n",
      " tensor([[1., 0., 1., 1.],\n",
      "        [1., 0., 1., 1.],\n",
      "        [1., 0., 1., 1.],\n",
      "        [1., 0., 1., 1.]]) \n",
      "\n"
     ]
    }
   ],
   "source": [
    "#增加Tensor\n",
    "#张量逐元素相乘\n",
    "print(f\"tensor.mul(tensor) \\n {tensor.mul(tensor)} \\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor.matmul(tensor.T) \n",
      " tensor([[3., 3., 3., 3.],\n",
      "        [3., 3., 3., 3.],\n",
      "        [3., 3., 3., 3.],\n",
      "        [3., 3., 3., 3.]]) \n",
      "\n",
      "tensor @ tensor.T \n",
      " tensor([[3., 3., 3., 3.],\n",
      "        [3., 3., 3., 3.],\n",
      "        [3., 3., 3., 3.],\n",
      "        [3., 3., 3., 3.]])\n"
     ]
    }
   ],
   "source": [
    "#张量和张量的转置的乘\n",
    "print(f\"tensor.matmul(tensor.T) \\n {tensor.matmul(tensor.T)} \\n\")\n",
    "#等价语句:\n",
    "print(f\"tensor @ tensor.T \\n {tensor @ tensor.T}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1., 0., 1., 1.],\n",
      "        [1., 0., 1., 1.],\n",
      "        [1., 0., 1., 1.],\n",
      "        [1., 0., 1., 1.]]) \n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[6., 5., 6., 6.],\n",
       "        [6., 5., 6., 6.],\n",
       "        [6., 5., 6., 6.],\n",
       "        [6., 5., 6., 6.]])"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#原地操作（不建议使用）\n",
    "tensor=torch.ones(4,4)\n",
    "tensor[:,1]=0\n",
    "print(tensor,'\\n')\n",
    "tensor.add_(5)\n",
    "tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "t:tensor([1., 1., 1., 1., 1.])\n",
      "n:[1. 1. 1. 1. 1.]\n"
     ]
    }
   ],
   "source": [
    "#numpy数组转化为Tensor\n",
    "t=torch.ones(5)\n",
    "print(f\"t:{t}\")\n",
    "\n",
    "n=t.numpy()\n",
    "print(f\"n:{n}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "t:tensor([2., 2., 2., 2., 2.])\n",
      "n:[2. 2. 2. 2. 2.]\n",
      "t:tensor([3., 3., 3., 3., 3.])\n",
      "n:[3. 3. 3. 3. 3.]\n"
     ]
    }
   ],
   "source": [
    "#tensor的改变会反映在转换后的numpy数组中\n",
    "t.add_(1)\n",
    "print(f\"t:{t}\")\n",
    "print(f\"n:{n}\")\n",
    "t.add_(1)\n",
    "print(f\"t:{t}\")\n",
    "print(f\"n:{n}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "t: tensor([2., 2., 2., 2., 2.], dtype=torch.float64)\n",
      "n: [2. 2. 2. 2. 2.]\n"
     ]
    }
   ],
   "source": [
    "#numpy转Tensor\n",
    "n=np.ones(5)\n",
    "t=torch.from_numpy(n)\n",
    "#同样会反映\n",
    "np.add(n, 1, out=n)\n",
    "print(f\"t: {t}\")\n",
    "print(f\"n: {n}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 题目"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.张量创建与基础"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1., 1., 1.],\n",
      "        [1., 1., 1.],\n",
      "        [1., 1., 1.]])\n",
      "tensor([[2., 2., 2.],\n",
      "        [2., 2., 2.],\n",
      "        [2., 2., 2.]])\n",
      "tensor([[1.5000, 1.5000, 1.5000],\n",
      "        [1.5000, 1.5000, 1.5000],\n",
      "        [1.5000, 1.5000, 1.5000]])\n"
     ]
    }
   ],
   "source": [
    "#创建\n",
    "t1=torch.ones(3,3)\n",
    "print(t1)\n",
    "\n",
    "#所有元素乘2\n",
    "t1=t1*2\n",
    "print(t1)\n",
    "\n",
    "#减去\n",
    "t1=t1-t1/4\n",
    "print(t1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. 索引与切片"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.7476, 0.4022, 0.3695, 0.0197, 0.0022],\n",
      "        [0.9305, 0.0982, 0.2617, 0.9344, 0.8546],\n",
      "        [0.0993, 0.4415, 0.3150, 0.1663, 0.3999],\n",
      "        [0.2127, 0.6724, 0.2030, 0.9079, 0.5414]]) \n",
      "\n",
      "tensor([[0.7476, 0.4022, 0.3695, 0.0197, 0.0022],\n",
      "        [0.9305, 0.0982, 0.2617, 0.9344, 0.8546]]) \n",
      "\n",
      "tensor([[0.3695, 0.0197, 0.0022],\n",
      "        [0.2617, 0.9344, 0.8546],\n",
      "        [0.3150, 0.1663, 0.3999],\n",
      "        [0.2030, 0.9079, 0.5414]]) \n",
      "\n",
      "tensor([[ 0.7476,  0.4022, -1.0000,  0.0197,  0.0022],\n",
      "        [ 0.9305,  0.0982,  0.2617, -1.0000,  0.8546],\n",
      "        [ 0.0993,  0.4415,  0.3150,  0.1663,  0.3999],\n",
      "        [ 0.2127,  0.6724,  0.2030,  0.9079,  0.5414]]) \n",
      "\n"
     ]
    }
   ],
   "source": [
    "#给定随机张量\n",
    "t2=torch.rand(4,5)\n",
    "print(t2,'\\n')\n",
    "\n",
    "#提取前两行\n",
    "temp=t2[[0,1],:]\n",
    "print(temp,'\\n')\n",
    "\n",
    "#提取后三列\n",
    "temp=t2[:,[-3,-2,-1]]\n",
    "print(temp,'\\n')\n",
    "\n",
    "#1行3列、2行4列设为-1\n",
    "t2[0,2]=t2[1,3]=-1\n",
    "print(t2,'\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. 矩阵乘法"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.1531, 0.2218, 0.6731],\n",
      "        [0.5744, 0.5246, 0.0841]]) \n",
      "\n",
      "tensor([[0.0810, 0.8807],\n",
      "        [0.7769, 0.7713],\n",
      "        [0.5091, 0.3320]]) \n",
      "\n",
      "tensor([[0.5274, 0.5294],\n",
      "        [0.4969, 0.9383]]) \n",
      "\n",
      "torch.Size([2, 2]) \n",
      "\n"
     ]
    }
   ],
   "source": [
    "#创建A\n",
    "a=torch.rand(2,3)\n",
    "print(a,'\\n')\n",
    "#创建B\n",
    "b=torch.rand(3,2)\n",
    "print(b,'\\n')\n",
    "\n",
    "#矩阵相乘\n",
    "m=a.matmul(b)\n",
    "print(m,'\\n')\n",
    "print(m.shape,'\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. 统计操作"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0.2462, 0.4794, 0.1639, 0.5403, 0.6304, 0.6053, 0.6320, 0.4510, 0.2778,\n",
      "        0.5303]) \n",
      "\n",
      "均值: 0.4557\n",
      "标准差: 0.1693\n",
      "最大值: 0.6320, 索引: 6\n",
      "最小值: 0.1639, 索引: 2\n"
     ]
    }
   ],
   "source": [
    "#创建\n",
    "t4=torch.rand(10,)\n",
    "print(t4,'\\n')\n",
    "\n",
    "mean=t4.mean() #均值\n",
    "std=t4.std() #标准差\n",
    "max_val, max_idx = torch.max(t4, dim=0)  # 最大值及其索引\n",
    "min_val, min_idx = torch.min(t4, dim=0)  # 最小值及其索引\n",
    "\n",
    "print(f\"均值: {mean:.4f}\")\n",
    "print(f\"标准差: {std:.4f}\")\n",
    "print(f\"最大值: {max_val:.4f}, 索引: {max_idx.item()}\")\n",
    "print(f\"最小值: {min_val:.4f}, 索引: {min_idx.item()}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5. 形状变换与广播"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.9595, 0.5759, 0.7973, 0.4766],\n",
      "        [0.2544, 0.6600, 0.8836, 0.5635],\n",
      "        [0.4927, 0.9695, 0.9710, 0.2926],\n",
      "        [0.7057, 0.5647, 0.2815, 0.1466],\n",
      "        [0.2417, 0.5393, 0.6310, 0.3542]]) \n",
      "\n",
      "tensor([[0.9595, 0.5759, 0.7973, 0.4766, 0.2544, 0.6600, 0.8836, 0.5635, 0.4927,\n",
      "         0.9695],\n",
      "        [0.9710, 0.2926, 0.7057, 0.5647, 0.2815, 0.1466, 0.2417, 0.5393, 0.6310,\n",
      "         0.3542]]) \n",
      "\n"
     ]
    }
   ],
   "source": [
    "#创建\n",
    "t5=torch.rand(5,4)\n",
    "print(t5,'\\n')\n",
    "\n",
    "#转换形状\n",
    "temp=t5.reshape(2,10)\n",
    "print(temp,'\\n')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[2],\n",
      "        [2],\n",
      "        [2]]) \n",
      "\n",
      "tensor([[3, 3, 3, 3]]) \n",
      "\n",
      "tensor([[5, 5, 5, 5],\n",
      "        [5, 5, 5, 5],\n",
      "        [5, 5, 5, 5]]) \n",
      "\n"
     ]
    }
   ],
   "source": [
    "#创建\n",
    "a=torch.full((3,1),2)\n",
    "print(a,'\\n')\n",
    "\n",
    "b=torch.full((1,4),3)\n",
    "print(b,'\\n')\n",
    "\n",
    "#广播相加\n",
    "c=a+b\n",
    "print(c,'\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. 梯度计算"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([2., 3.], requires_grad=True) \n",
      "\n",
      "tensor([17., 34.], grad_fn=<AddBackward0>) \n",
      "\n",
      "张量 t: tensor([2., 3.], requires_grad=True)\n",
      "函数 y: tensor([17., 34.], grad_fn=<AddBackward0>)\n",
      "梯度 t.grad: tensor([14., 20.])\n",
      "计算得到梯度: tensor([14., 20.])\n",
      "梯度是否一致: True\n"
     ]
    }
   ],
   "source": [
    "#创建\n",
    "x1=[2.0,3.0]\n",
    "t=torch.tensor(x1,requires_grad=True) #启用梯度跟踪\n",
    "print(t,'\\n')\n",
    "\n",
    "#函数定义\n",
    "y =3*t**2+2*t+1\n",
    "print(y,'\\n')\n",
    "\n",
    "#梯度计算\n",
    "y_sum=y.sum()\n",
    "y_sum.backward()#计算梯度\n",
    "\n",
    "# 打印结果\n",
    "print(\"张量 t:\", t)\n",
    "print(\"函数 y:\", y)\n",
    "print(\"梯度 t.grad:\", t.grad)\n",
    "\n",
    "# 验证梯度是否正确\n",
    "expected_grad = 6 * t.detach() + 2\n",
    "print(\"计算得到梯度:\", expected_grad)\n",
    "print(\"梯度是否一致:\", torch.allclose(t.grad, expected_grad))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Deep",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
